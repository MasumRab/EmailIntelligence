{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Recover Lost Backend Modules and Features",
        "description": "Investigate the Git history to find, recover, and reintegrate backend modules and features that were lost during recent commits and merges. This is a prerequisite to ensure the subsequent migration and refactoring work is performed on a complete and correct codebase.",
        "details": "Begin by creating a comprehensive list of expected features and modules based on the PRD and any existing design documents. Use Git commands to audit the repository's history for lost code. Key commands include `git reflog` to find dangling commits, `git log --diff-filter=D --summary` to find deleted files, and `git log -S'<unique_code_string>'` to search for code that has disappeared. Once found, use `git checkout <commit_hash> -- <file_path>` or `git cherry-pick <commit_id>` to restore the code into a dedicated recovery branch. All recovered code must be documented in a new file, e.g., `docs/recovery_log.md`.",
        "testStrategy": "Create a new branch for recovery. After restoring files/code, run the existing test suite to check for immediate breakages. For any recovered feature that lacks test coverage, write minimal unit or integration tests to confirm its basic functionality is restored. The primary goal is to reintegrate the code and ensure the application remains stable. A peer review of the recovered code against the recovery log is mandatory before merging.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Recovery Branch and Compile Lost Feature Checklist",
            "description": "Prepare the workspace for code recovery by creating a new Git branch. Review `docs/PRD.md` to create a comprehensive checklist of all features and modules that are expected to be present in the backend.",
            "dependencies": [],
            "details": "Create a new branch named `feature/recover-lost-modules`. Create a new file `docs/recovery_log.md` and populate it with a 'Lost Features Checklist' section based on the analysis of `docs/PRD.md`, including 'Smart Filtering Engine', 'Smart Retrieval Engine', and 'Email Summarization AI'.",
            "status": "done",
            "testStrategy": "N/A - This is a preparatory task. Verification will be done by checking for the existence and content of the new branch and the `docs/recovery_log.md` file."
          },
          {
            "id": 2,
            "title": "Audit Git History to Identify Commits Containing Lost Modules",
            "description": "Use Git forensics commands to search the repository's history for commits related to the lost features identified in the checklist. Document the findings in the recovery log.",
            "dependencies": [
              1
            ],
            "details": "Use commands like `git log --diff-filter=D --summary`, `git log -S'SmartFilteringEngine'`, `git log -S'SmartRetrievalEngine'`, and `git reflog` to find commits where files like `smart_filters.py` and `smart_retrieval.py` were deleted or last existed. Record the relevant commit hashes and file paths in `docs/recovery_log.md`.",
            "status": "done",
            "testStrategy": "Verification involves reviewing the `docs/recovery_log.md` file to ensure it contains a list of commit hashes and file paths that verifiably contain the lost code when inspected with `git show <commit_hash>:<file_path>`."
          },
          {
            "id": 3,
            "title": "Restore Core AI Modules: 'smart_filters' and 'smart_retrieval'",
            "description": "Restore the `smart_filters.py` and `smart_retrieval.py` modules from the commits identified during the Git audit into the recovery branch.",
            "dependencies": [
              2
            ],
            "details": "Using the commit hashes documented in `docs/recovery_log.md`, execute `git checkout <commit_hash> -- <path/to/file>` for both `smart_filters.py` and `smart_retrieval.py` to restore them to the `backend/` directory (or their original location).",
            "status": "done",
            "testStrategy": "After checkout, verify the files `backend/smart_filters.py` and `backend/smart_retrieval.py` exist in the working directory and are not empty. Run the application to ensure it does not immediately crash due to syntax errors in the restored files."
          },
          {
            "id": 4,
            "title": "Restore Additional Lost Modules (e.g., Email Summarization)",
            "description": "Restore any other identified lost modules, such as the email summarization feature and related utility functions, using the same Git recovery process.",
            "dependencies": [
              2
            ],
            "details": "Based on the git audit, restore other missing files, such as a module for the 'Email Summarization AI' (e.g., `backend/summarizer.py`) and any helper utilities they depended on. Use `git checkout <commit_hash> -- <path/to/file>` and update `docs/recovery_log.md` with the status of each restored item.",
            "status": "done",
            "testStrategy": "Verify that the additional restored files (e.g., `backend/summarizer.py`) exist in the working directory. Check file contents to ensure they are not empty and appear to be complete."
          },
          {
            "id": 5,
            "title": "Integrate and Verify All Recovered Backend Modules",
            "description": "Ensure all restored modules are correctly integrated into the application. This includes fixing imports, running existing tests, and adding minimal new tests for uncovered restored code to confirm basic functionality.",
            "dependencies": [
              3,
              4
            ],
            "details": "Update `backend/main.py` and other necessary files to import and wire up endpoints for the restored modules. Execute the full existing test suite (`pytest tests/`). If restored features like `smart_filters` lack tests, add a new test file (e.g., `tests/test_smart_filters.py`) with a single test case to confirm a basic function call succeeds.",
            "status": "done",
            "testStrategy": "The primary goal is successful integration. All existing tests must pass. Any new minimal tests for recovered features must also pass. A final manual check via `uvicorn backend.main:app` should show the application starts without errors."
          }
        ]
      },
       {
         "id": 2,
         "title": "Backend Migration from 'backend' to 'src/backend'",
         "description": "Execute the complete structural migration of the legacy 'backend' package to the new modular architecture under 'src/backend'. This is a critical architectural improvement to modernize the codebase and enable further development.",
         "details": "1. Create a new branch from the scientific branch (which contains the most advanced backend implementation). 2. Physically move the entire `backend` directory into `src/` and rename it to `src/backend`. 3. Perform a project-wide find-and-replace to update all Python import statements from `from backend...` to `from src.backend...`. Use a tool like `sed`, `grep`, or an IDE's refactoring capabilities. 4. Update any configuration files that reference the old path. This includes `PYTHONPATH` definitions in Dockerfiles (`ENV PYTHONPATH=\"/app/src:$PYTHONPATH\"`), `docker-compose.yml`, CI/CD pipeline scripts (e.g., `.github/workflows/ci.yml`), and potentially `pyproject.toml` if using editable installs. 5. After all tests pass, delete the original top-level `backend` directory. 6. Ensure `src/__init__.py` and `src/backend/__init__.py` exist to make them valid packages.",
         "testStrategy": "The primary validation method is comprehensive regression testing. Run the full existing test suite and ensure 100% of tests pass. Perform a manual smoke test of the application by starting it and hitting key API endpoints using Postman or cURL to confirm it is fully functional. The application's behavior must be identical to the pre-migration state. No new feature tests are required for this task.",
         "priority": "high",
         "dependencies": [
           1
         ],
         "status": "pending",
         "subtasks": [
           {
             "id": 1,
             "title": "Create migration branch from scientific",
             "description": "Create feature/backend-to-src-migration branch from scientific branch",
             "dependencies": [],
             "details": "Execute `git checkout scientific && git pull && git checkout -b feature/backend-to-src-migration`",
             "status": "pending",
             "testStrategy": "Verify branch creation and that it contains all scientific backend modules"
           },
           {
             "id": 2,
             "title": "Move backend directory to src/backend",
             "description": "Physically relocate backend directory to src/backend structure",
             "dependencies": [1],
             "details": "Execute `mkdir -p src && mv backend src/backend && touch src/__init__.py src/backend/__init__.py`",
             "status": "pending",
             "testStrategy": "Verify directory structure and package files exist"
           },
           {
             "id": 3,
             "title": "Update all Python import statements",
             "description": "Replace all `from backend.` imports with `from src.backend.`",
             "dependencies": [2],
             "details": "Use sed/grep to find and replace import statements across the codebase",
             "status": "pending",
             "testStrategy": "Run static analysis to verify no import errors"
           },
           {
             "id": 4,
             "title": "Update configuration files",
             "description": "Update PYTHONPATH and other references in config files",
             "dependencies": [3],
             "details": "Update Dockerfiles, docker-compose.yml, CI/CD configs, and pyproject.toml",
             "status": "pending",
             "testStrategy": "Verify configuration files reference correct paths"
           },
           {
             "id": 5,
             "title": "Run full test suite and smoke tests",
             "description": "Execute comprehensive testing to ensure migration success",
             "dependencies": [4],
             "details": "Run pytest, start application, test API endpoints",
             "status": "pending",
             "testStrategy": "All tests pass, application starts, API endpoints functional"
           },
           {
             "id": 6,
             "title": "Clean up original backend directory",
             "description": "Remove obsolete top-level backend directory",
             "dependencies": [5],
             "details": "Execute `rm -rf backend` after validation",
             "status": "pending",
             "testStrategy": "Verify backend directory removed, no broken references"
           }
         ]
            },
            {
              "id": 2,
              "title": "Integrate Backend Migration",
              "description": "Merge feature/backend-to-src-migration from scientific branch and update all imports",
              "status": "pending",
              "dependencies": [],
              "details": "Extract rule_parsers.py, filter_evaluators.py, data_transformers.py from smart_filters.py\nExtract query_builders.py, ranking_algorithms.py, source_integrations.py from smart_retrieval.py\nImplement dependency injection and maintain 100% test coverage using scientific's testing framework",
              "testStrategy": "Unit tests for each new module, integration tests for refactored functionality, leverage scientific's 90+ test files"
            },
            {
              "id": 2,
              "title": "Integrate Backend Migration",
              "description": "Merge feature/backend-to-src-migration from scientific branch and update all imports",
              "status": "pending",
              "dependencies": [],
              "details": "Validate migration completeness using scientific's advanced backend (20+ modules), update import references, merge to scientific, run full test suite",
              "testStrategy": "Import validation, regression testing, functionality verification using scientific's comprehensive testing"
            },
            {
              "id": 3,
        "title": "Implement Enhanced Security: RBAC, MFA, Session Management, and Auditing",
        "description": "Upgrade the existing JWT-based authentication system to include Role-Based Access Control (RBAC), Multi-Factor Authentication (MFA), secure session management, and audit logging for sensitive operations, following modern security best practices.",
        "details": "This task will be implemented on the new `src/backend` structure. 1. **RBAC**: Extend the User model/schema with a `role: str` field. Create a FastAPI dependency that checks roles. Example: `def require_role(required_roles: list[str]): def dependency(current_user: User = Depends(get_current_user)): if current_user.role not in required_roles: raise HTTPException(403); return current_user; return dependency`. Protect routes with `Depends(require_role(['admin']))`. 2. **MFA**: Integrate `pyotp~=2.9.0`. Add `mfa_secret: str` and `mfa_enabled: bool` to the User model. Create endpoints: `POST /auth/mfa/generate` (returns a `pyotp.totp.TOTP(...).provisioning_uri(...)`) and `POST /auth/mfa/verify` (checks code). Update the login flow to require a second step if MFA is enabled. 3. **Session Management**: Use `redis-py~=5.0.1`. On login, store a session token in Redis with a TTL (e.g., 1h). The JWT issued to the client can be short-lived (e.g., 15m). A middleware will validate the session token against Redis on each request, allowing for immediate session revocation. 4. **Audit Logging**: Use Python's `logging` module to create a dedicated 'audit' logger. Create a middleware or decorator to apply to sensitive endpoints. The log should capture `timestamp`, `user_id`, `source_ip`, `action`, and `outcome` in a structured format (JSON is recommended).",
        "testStrategy": "Develop unit tests for each new security feature. For RBAC, test that users with incorrect roles are denied access (403). For MFA, test the TOTP generation and validation logic. For Session Management, test session expiry and revocation. For Audit Logging, verify that sensitive actions are logged correctly to the specified output. Create integration tests that simulate a full login flow with MFA and subsequent access to a role-protected endpoint.",
        "priority": "high",
        "dependencies": [
          2
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "Refactor High-Complexity Modules and Duplicated Code",
        "description": "Improve code quality by refactoring large modules (`smart_filters.py`, `smart_retrieval.py`), reducing code duplication in AI engine modules, and simplifying high-complexity functions as identified in the PRD, applying research-backed refactoring best practices.",
        "status": "pending",
        "dependencies": [
          2
        ],
        "priority": "medium",
        "details": "This refactoring will be performed on the new `src/backend` structure, incorporating modern refactoring best practices and an incremental, test-driven approach.\n\n1.  **Module Splitting & Incremental Refactoring for `smart_filters.py` and `smart_retrieval.py`**:\n    *   **Goal**: Decompose these large, monolithic modules (`src/backend/smart_filters.py` at 1598 lines and `src/backend/smart_retrieval.py` at 1198 lines) into smaller, more cohesive, and single-responsibility modules, strictly adhering to the Single Responsibility Principle (SRP) and aiming for high cohesion and low coupling.\n    *   **Strategy**: Employ a phased 'Extract Module' or 'Extract Class' refactoring pattern. For each large module:\n        *   **Identify Cohesive Units**: Systematically analyze the existing files to identify distinct logical concerns, architectural layers, or sets of closely related functions/data that exhibit 'Feature Envy' (methods using data from other objects more than their own) or form 'Data Clumps'. These are prime candidates for extraction.\n        *   **Create Dedicated Packages**: Create a dedicated package directory, e.g., `src/backend/smart_filters/` and `src/backend/smart_retrieval/`. This clearly delineates the new module boundaries.\n        *   **Module Breakdown Examples**:\n            *   `smart_filters.py`: Potential modules include `rule_parsers.py` (for parsing rule definitions from configuration, e.g., `src/backend/smart_filters/rule_parsers.py`), `filter_evaluators.py` (for applying filter logic), `data_transformers.py` (for preparing data for filtering), `persistence.py` (for loading/saving filter configurations).\n            *   `smart_retrieval.py`: Potential modules include `query_builders.py` (for constructing retrieval queries), `ranking_algorithms.py` (for scoring and ordering results), `source_integrations.py` (for interfacing with data sources, potentially using 'Ports and Adapters' pattern), `result_processors.py` (for post-processing retrieved items).\n        *   **Incremental Steps**: For each identified concern, move the related functions, classes, and their associated data into a new, dedicated Python file within its respective package directory. Update all internal and external imports to reflect the new structure. Each extraction should be a small, self-contained, and testable commit.\n        *   **Public API Control**: Utilize `__init__.py` within these new packages to define and control the public API, exposing only necessary functions/classes to avoid tightly coupling consumers to internal module structures (e.g., using `from .sub_module import func_name` in `__init__.py` to expose `func_name` at the package level).\n\n2.  **Reduce Code Duplication in AI Engine**:\n    *   **Goal**: Eliminate the 165-195 reported duplication occurrences across the AI engine modules (e.g., `src/backend/ai/email_filter_node.py` and other related AI components), adhering to the Don't Repeat Yourself (DRY) principle.\n    *   **Strategy**: Identify recurring code blocks, patterns, and boilerplate. Apply 'Extract Method', 'Extract Class', or 'Extract Superclass' refactorings to abstract common logic into shared, reusable utility functions and classes.\n    *   **Location**: Create a new module `src/backend/ai/utils.py` for general AI-related helper functions specific to the AI domain. For broader, cross-cutting utilities (e.g., data validation, common error handling), consider `src/backend/utils/common.py`.\n    *   **Examples of Abstraction**: Look for repeated data validation logic (e.g., using Pydantic models for input validation), common pre-processing steps for text/email content (e.g., tokenization, normalization), standardized error handling patterns, logging boilerplate, or shared data access patterns. Prioritize creating small, pure functions where inputs map deterministically to outputs, making them easily testable and reusable.\n\n3.  **Function Simplification (`setup_dependencies`, `migrate_sqlite_to_json`, `run`)**:\n    *   **Goal**: Significantly reduce the cyclomatic complexity of `setup_dependencies` (complexity 21, likely found in `src/backend/dependencies.py`), `migrate_sqlite_to_json` (complexity 17, likely in `src/backend/utils/database.py`), and the `run` method in `src/backend/ai/email_filter_node.py` (complexity 16), improving readability and maintainability.\n    *   **Strategy**: Apply the 'Extract Method' refactoring pattern incrementally. Break down these large functions into smaller, private helper functions (conventionally prefixed with `_`) that each encapsulate a single, distinct responsibility or logical step. Consider breaking down based on:\n        *   **Sequence of Operations**: Separate distinct sequential steps.\n        *   **Decision Points**: Extract complex conditional logic into its own method.\n        *   **Loop Processing**: Encapsulate the body of a loop or its initialization/finalization.\n    *   **Specifics**:\n        *   `setup_dependencies` (in `src/backend/dependencies.py`): Extract initialization steps into private methods like `_initialize_database_connection()`, `_load_application_config()`, `_setup_logging()`, `_register_event_handlers()`, etc.\n        *   `migrate_sqlite_to_json` (in `src/backend/utils/database.py`): Decompose into steps such as `_read_data_from_sqlite(db_path)`, `_transform_row_to_json_record(row)`, `_write_json_records_to_file(records, output_path)`.\n        *   `run` (in `src/backend/ai/email_filter_node.py`): Identify distinct phases of its execution lifecycle, such as `_ingest_email_messages()`, `_preprocess_message(message)`, `_apply_ai_filters(processed_message)`, `_collate_results(filter_results)`, `_store_or_dispatch_results(final_results)`. Each phase should become a separate, focused private method.\n    *   **Naming**: Ensure extracted methods have descriptive names that clearly convey their purpose and avoid generic names. If a function has too many parameters after extraction, consider 'Introduce Parameter Object' refactoring.\n\n4.  **Continuous Integration with Refactoring**: Throughout this task, maintain small, atomic commits for each refactoring step, ensuring that the system remains in a working state after every commit. This facilitates easy rollback and debugging.",
        "testStrategy": "This is a pure refactoring task; no new functionality should be introduced, and the external behavior of the system must remain unchanged. A robust test-driven refactoring strategy will be employed:\n1.  **Pre-refactoring Characterization Tests (Golden Master)**: Before initiating any changes, ensure all target modules (`src/backend/smart_filters.py`, `src/backend/smart_retrieval.py`, `src/backend/ai/email_filter_node.py`, `src/backend/dependencies.py`, `src/backend/utils/database.py`, and any relevant AI engine modules) have comprehensive test coverage. If coverage is lacking, write 'characterization tests' (also known as 'golden master tests') to rigorously capture and lock in the current observable behavior, even if it's imperfect. These tests are critical to ensure functional equivalence post-refactoring.\n2.  **Incremental Testing and Verification**: After *each small, atomic refactoring step* (e.g., extracting a single method, moving a set of functions to a new module, changing an import), immediately run the relevant test suite (including characterization tests) to catch regressions early. This iterative testing approach is fundamental to safe and effective refactoring. The goal is to always have a green test suite.\n3.  **Behavioral Preservation**: All existing tests for the modified code must pass without any alterations to the tests themselves. The external behavior of the system should remain unchanged. New tests should only be added to cover newly extracted units or to improve coverage where it was initially insufficient for safe refactoring.\n4.  **Static Analysis Integration and Monitoring**: \n    *   **Baseline**: Run a static analysis tool like `radon` (`radon cc -a .` for cyclomatic complexity and `radon mi -a .` for maintainability index) across the codebase (or targeted modules) *before* starting the refactoring to establish a quantitative baseline for complexity and maintainability.\n    *   **Continuous Monitoring**: Integrate these checks into a pre-commit hook or CI/CD pipeline if possible. Alternatively, run them regularly during the refactoring process to monitor progress, ensuring complexity metrics decrease and maintainability indices improve. Tools like `pylint` and `flake8` should also be run to enforce coding standards and identify potential issues.\n    *   **Post-refactoring Verification**: Re-run `radon`, `pylint`, and `flake8` after the refactoring is complete to quantify the reduction in cyclomatic complexity, confirm improved maintainability, and verify adherence to coding standards, thereby proving the task's success.\n5.  **Performance Check**: Conduct basic performance smoke tests or run existing benchmarks to ensure that the refactoring has not introduced any significant performance degradations, especially in critical paths involving the AI engine or data processing. Tools like `cProfile` can be used for targeted analysis if needed.",
        "subtasks": null
      },
      {
        "id": 5,
        "title": "Align Feature Branches with Scientific Branch",
        "description": "Systematically align multiple feature branches with the scientific branch to ensure code consistency, reduce future merge conflicts, and propagate the latest changes. This process will carefully preserve the key business logic and unique features of each feature branch, focusing updates primarily on architectural and common files from the scientific branch to minimize unnecessary conflicts, while ensuring feature-specific work is maintained.",
        "status": "pending",
        "dependencies": [
          1,
          2,
          3,
          4
        ],
        "priority": "high",
        "details": "This high-priority task involves a coordinated effort to bring all active feature branches up-to-date with the stable 'scientific' branch. The process will be executed in three main parts.\n\nPart 1: Feature Branch Assessment\n- Use `git branch --remote` and `git log` to identify all active branches diverging from 'scientific'.\n- Create a shared checklist (e.g., a repository markdown file) of branches to be aligned, including: feature/backlog-ac-updates, fix/import-error-corrections, docs-cleanup, feature/search-in-category, feature/merge-clean, feature/merge-setup-improvements.\n- Prioritize the branches based on importance and complexity of divergence.\n\nPart 2: Alignment Execution\n- For each branch, create a local backup first (e.g., `git branch <branch-name>-backup-pre-align`).\n- Check out the feature branch (`git checkout <feature-branch>`).\n- For public or shared branches, use a merge strategy to preserve history: `git merge scientific`.\n- Systematically resolve any merge conflicts, using visual merge tools for clarity. Document complex resolutions in the merge commit message.\n\nPart 3: Validation and Documentation\n- After each successful alignment, push the updated branch to the remote repository.\n- Create a Pull Request for each aligned branch to allow for code review and automated CI checks.\n- Update the central alignment checklist to reflect the status of each branch.",
        "testStrategy": "Validation will focus on ensuring no regressions are introduced during the alignment process.\n1. Before beginning alignment on a branch, run its existing test suite to establish a baseline.\n2. After the merge/rebase is completed and all conflicts are resolved locally, run the full project test suite. All tests must pass.\n3. Perform a manual smoke test on the core functionality provided by the feature branch to ensure it has not been broken by the merge.\n4. Upon pushing the aligned branch and opening a PR, the continuous integration (CI) pipeline must pass all checks, including linting, unit tests, and integration tests. This CI pass is a mandatory success criterion for each branch.",
        "subtasks": [
          {
            "id": 1,
            "title": "Identify Divergent Branches and Create Alignment Plan",
            "description": "Analyze all remote feature branches to identify which have diverged from the 'scientific' branch. Document these branches in a new markdown file to serve as a master checklist for the alignment process.",
            "dependencies": [],
            "details": "Use 'git branch --remote' and 'git log' to compare each feature branch with 'scientific'. Create a new file named `ALIGNMENT_CHECKLIST.md` in the project root. List the branches to be aligned, including `feature/backlog-ac-updates`, `fix/import-error-corrections`, `docs-cleanup`, `feature/search-in-category`, `feature/merge-clean`, and `feature/merge-setup-improvements`. Add columns for status and notes.",
            "status": "pending",
            "testStrategy": "Verify the generated `ALIGNMENT_CHECKLIST.md` file is present in the repository and accurately lists all the feature branches mentioned in the task description."
          },
          {
            "id": 2,
            "title": "Create Local Backups of All Targeted Feature Branches",
            "description": "Before initiating any merge operations, create local backup copies of all feature branches listed in the alignment checklist. This provides a critical safety net and a simple rollback point.",
            "dependencies": [
              1
            ],
            "details": "For each branch identified in `ALIGNMENT_CHECKLIST.md`, execute the command `git branch <branch-name>-backup-pre-align`. For example, for 'feature/backlog-ac-updates', run `git branch feature/backlog-ac-updates-backup-pre-align`. Verify backup creation with `git branch`.",
            "status": "pending",
            "testStrategy": "Run `git branch | grep -- '-backup-pre-align'` locally to confirm that a backup has been created for every branch listed in the alignment checklist."
          },
          {
            "id": 3,
            "title": "Align 'feature/backlog-ac-updates' with 'scientific' Branch",
            "description": "Perform a merge of the 'scientific' branch into the 'feature/backlog-ac-updates' branch. This will propagate the latest stable changes into the feature branch.",
            "dependencies": [
              2
            ],
            "details": "First, checkout the feature branch using `git checkout feature/backlog-ac-updates`. Then, run `git merge scientific`. Systematically resolve any merge conflicts that arise using a visual merge tool and document complex resolutions in the merge commit message.",
            "status": "pending",
            "testStrategy": "Run the project's test suite on the branch before the merge to establish a baseline. After the merge and conflict resolution, run the full test suite again to ensure no regressions have been introduced."
          },
          {
            "id": 4,
            "title": "Align 'fix/import-error-corrections' with 'scientific' Branch",
            "description": "Perform a merge of the 'scientific' branch into the 'fix/import-error-corrections' branch to ensure the fix is compatible with the latest codebase.",
            "dependencies": [
              2
            ],
            "details": "Checkout the fix branch using `git checkout fix/import-error-corrections`. Execute `git merge scientific`. Carefully resolve any merge conflicts, paying special attention to file path and import statement changes given the nature of this branch.",
            "status": "pending",
            "testStrategy": "Before merging, run tests to confirm the fix works as intended. After merging, run the full test suite, especially integration tests that might fail due to incorrect module paths or circular dependencies."
          },
          {
            "id": 5,
            "title": "Align 'feature/search-in-category' with 'scientific' Branch",
            "description": "Merge the latest changes from the 'scientific' branch into the 'feature/search-in-category' branch, resolving any resulting conflicts.",
            "dependencies": [
              2
            ],
            "details": "Switch to the feature branch with `git checkout feature/search-in-category`. Run `git merge scientific` to start the alignment. Resolve all merge conflicts and ensure the new search functionality integrates correctly with the latest base code from 'scientific'.",
            "status": "pending",
            "testStrategy": "Run existing tests on the branch to get a baseline. After the merge, run the full test suite. Additionally, perform a manual smoke test of the search-in-category feature to confirm its behavior remains correct."
          },
          {
            "id": 6,
            "title": "Align Remaining Minor Branches with 'scientific'",
            "description": "Perform the alignment process for the remaining, lower-priority branches: 'docs-cleanup', 'feature/merge-clean', and 'feature/merge-setup-improvements'.",
            "dependencies": [
              2
            ],
            "details": "Sequentially process each branch. For each one, use `git checkout <branch-name>`, then `git merge scientific`. Resolve any conflicts that may arise. Given their scope, these branches are expected to have fewer conflicts.",
            "status": "pending",
            "testStrategy": "For 'docs-cleanup', a visual inspection of rendered documentation changes is sufficient. For 'feature/merge-clean' and 'feature/merge-setup-improvements', the full project test suite must be run post-merge to validate integrity."
          },
          {
            "id": 7,
            "title": "Push Aligned Branches and Create Pull Requests",
            "description": "Push all the locally merged and validated feature branches to the remote repository. Create a corresponding Pull Request for each aligned branch to enable code review and trigger CI/CD pipelines.",
            "dependencies": [
              3,
              4,
              5,
              6
            ],
            "details": "For each successfully aligned branch, run `git push origin <branch-name> --force-with-lease` if rebase was used, or `git push` if merge was used. Subsequently, navigate to the repository's web UI and create a Pull Request for each branch, targeting 'scientific'.",
            "status": "pending",
            "testStrategy": "Confirm that a new Pull Request exists for each aligned branch. Check that the PR's 'Files changed' tab correctly reflects the merge from 'scientific' and that CI checks have been automatically triggered."
          },
          {
            "id": 8,
            "title": "Final Validation, Review, and Checklist Completion",
            "description": "Monitor the CI pipelines for all created Pull Requests, address any feedback from code reviews, and update the master checklist to reflect the completion of each branch alignment.",
            "dependencies": [
              1,
              7
            ],
            "details": "Review the CI build logs for each PR to ensure all tests pass. Address any code review comments by pushing new commits to the respective branches. After a PR is fully validated and approved, update its status to 'Completed' in the `ALIGNMENT_CHECKLIST.md` file.",
            "status": "pending",
            "testStrategy": "Final validation is successful when all created PRs have a 'green' build status, have been approved by at least one reviewer, and the `ALIGNMENT_CHECKLIST.md` file is updated to show all branches as 'Completed'."
          }
        ]
      },
      {
        "id": 6,
        "title": "Deep Integration & Refactoring: Align feature-notmuch-tagging-1 with Scientific, Enhance Data Platform, and Introduce Scalable AI Capabilities",
        "description": "Execute a comprehensive alignment of the `feature-notmuch-tagging-1` branch with the `scientific` branch, focusing on robust integration of the enhanced NotmuchDataSource, AI analysis, smart tagging, and full CRUD operations. This task not only involves updating architectural and common files from the `scientific` branch but also requires significant refactoring to ensure scalability, fault tolerance, and deep compatibility with existing data structures and the analytics ecosystem, while preserving and optimizing the feature branch's distinct functionalities. Special attention should be paid to data model evolution, performance under load, and comprehensive security hardening.",
        "status": "pending",
        "dependencies": [
          1,
          2,
          3,
          4
        ],
        "priority": "high",
        "details": "This task involves a multi-faceted integration, including architectural adjustments and new feature development:\n1.  **Strategic Branch Alignment & Conflict Resolution:** Initiate by rebasing `feature-notmuch-tagging-1` onto the latest `scientific` branch. Resolve all merge conflicts meticulously, especially in core data access and AI-related modules, ensuring `scientific`'s foundational stability while integrating feature-specific changes. Document all non-trivial conflict resolutions.\n2.  **Extended NotmuchDataSource Implementation & Data Model Evolution:** In `src/core/notmuch_data_source.py`, ensure the full DataSource interface is not only implemented (`delete_email`, `get_dashboard_aggregates`, `get_category_breakdown`) but also optimized for performance and large datasets. Review and propose necessary schema migrations or adaptations in the underlying data store to accommodate new Notmuch tagging and AI analysis metadata. Ensure `get_dashboard_aggregates` supports complex filtering and time-series aggregation efficiently.\n3.  **Scalable AI Analysis & Categorization Pipeline:** Integrate the AI-powered sentiment analysis and categorization logic as a highly scalable and fault-tolerant background process. This requires implementing a message queue (e.g., Kafka/RabbitMQ) for processing, robust retry mechanisms, and error queues for failed AI jobs. The AI model should support versioning and be configurable for different analysis types (e.g., multilingual). Consider model retraining and deployment strategies.\n4.  **Advanced SmartFilterManager Integration & Rule Engine Extension:** Beyond simple connection, extend `SmartFilterManager` to allow dynamic rule creation and persistence based on AI-derived tags and user-defined criteria. This may require a new domain-specific language (DSL) or configuration interface for defining and applying complex filtering rules that leverage Notmuch tags and AI insights.\n5.  **Hierarchical Tagging & Category Management System:** Implement comprehensive logic for tag-based category mapping, including support for hierarchical tags, tag synonyms, and user-defined categorization rules. This system should provide CRUD operations for tags and categories themselves, allowing for flexible taxonomy management.\n6.  **Distributed Observability & Performance Monitoring:** Integrate comprehensive error reporting, distributed tracing (e.g., OpenTelemetry), and advanced performance monitoring hooks for all new components. Define custom metrics for AI processing latency, accuracy, and background job throughput. Ensure all logs are structured and integrated with a centralized logging solution.\n7.  **End-to-End Security Hardening & Compliance:** Expand security enhancements beyond robust path validation to include input sanitization across all new data entry points, API authentication/authorization for any new internal/external endpoints, data encryption at rest and in transit for sensitive Notmuch data, and adherence to relevant data privacy regulations (e.g., GDPR, CCPA). Conduct a security review of the entire integration.\n8.  **Database Layer Adaptation & Optimization:** Update `src/core/database.py` with any necessary adjustments for compatibility with the enhanced data source, including new data types (e.g., JSONB for flexible metadata, vector embeddings for AI), optimized query patterns for the new aggregation methods, and ensuring transactional integrity for all tagging and AI-related operations. Implement database connection pooling and query caching where beneficial.\n9.  **API Exposure & Documentation:** If new capabilities are exposed via an API, ensure robust, versioned API endpoints are created and fully documented using OpenAPI/Swagger, including security considerations and usage examples.\n10. **Comprehensive Documentation:** Update all relevant design documents, architectural diagrams, and user guides to reflect the new NotmuchDataSource capabilities, AI integration, and tagging system.",
        "testStrategy": "A rigorous and multi-layered testing strategy is required to ensure the stability, correctness, performance, and security of this complex integration:\n1.  **Expanded Regression Test Suite:** Execute a full regression test suite across the entire application to ensure no existing functionality is broken. This must include performance baselining before and after integration to identify any regressions in response times or resource consumption.\n2.  **Detailed Unit & Integration Tests for NotmuchDataSource:** Develop comprehensive unit tests covering all methods of the `NotmuchDataSource`, including edge cases for each (`delete_email` with non-existent IDs, `get_dashboard_aggregates` with various date ranges and filters, `get_category_breakdown` with empty data). Integration tests should thoroughly verify the `NotmuchDataSource`'s interaction with the actual database and `SmartFilterManager`.\n3.  **Advanced AI/Background Process Validation:** Create specific integration tests to verify the end-to-end flow of the background AI analysis and tagging processes. This includes testing message queue interactions, error handling for failed AI jobs (e.g., malformed input, AI model errors), retry mechanisms, and the persistence of AI-derived metadata. Validate AI model accuracy with a diverse test dataset, tracking false positives and negatives.\n4.  **Smart Filtering & Tagging System Validation:** Develop comprehensive tests for the `SmartFilterManager` and the new hierarchical tagging system. This includes validating dynamic rule creation, application, and persistence, as well as complex category mapping scenarios (e.g., overlapping tags, nested categories, tag deprecation).\n5.  **Observability System Verification:** Confirm that new performance metrics, distributed traces, and structured error logs are correctly generated, captured, and accessible through the centralized monitoring system. Validate alert configurations for critical errors and performance thresholds.\n6.  **Comprehensive Security Testing:** Beyond functional security tests, conduct vulnerability scanning, penetration testing simulations (e.g., SQL injection, XSS for new inputs if applicable, broken access control for new endpoints), and data privacy compliance checks. Verify all input sanitization and authorization rules.\n7.  **Performance, Load, and Stress Testing:** Conduct extensive performance testing, including load tests (simulating expected peak usage), stress tests (exceeding peak usage to find breaking points), and soak tests (long-duration tests to detect memory leaks or resource exhaustion). Focus on the `NotmuchDataSource` aggregation methods and AI background processing under high concurrency.\n8.  **Data Migration & Schema Evolution Testing:** Rigorously test any proposed database schema changes or data migrations. This includes testing forward compatibility (new code with old schema) and backward compatibility (old code with new schema, if necessary for rollback plans). Ensure data integrity and consistency throughout the migration process.\n9.  **User Acceptance Testing (UAT):** Plan and execute UAT sessions with key business stakeholders to validate that the new smart tagging, AI analysis results, and filtering capabilities meet business requirements and provide an intuitive user experience.\n10. **Continuous Integration/Continuous Deployment (CI/CD) Integration:** Ensure all newly developed tests, including unit, integration, and security checks, are integrated into the CI/CD pipeline for automated execution on every code change.",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Create Comprehensive Merge Validation Framework",
        "description": "Create a comprehensive validation framework to ensure all architectural updates have been properly implemented before merging scientific branch to main. This framework will leverage research-backed CI/CD practices to validate consistency, functionality, performance, and security across all components, specifically tailored for our Python/FastAPI application. This task is directly linked to the backlog item: `backlog/tasks/alignment/create-merge-validation-framework.md`.",
        "status": "pending",
        "dependencies": [],
        "priority": "high",
        "details": "This framework will integrate into the GitHub Actions CI/CD pipeline, triggered on pull requests to the `main` branch from `scientific`. It will encompass several layers of automated checks, including:\n1.  **Architectural Enforcement**: Static analysis to ensure `src/backend` adheres to defined module boundaries and import rules.\n2.  **Functional Correctness**: Execution of full unit/integration test suites for `src/backend` and end-to-end smoke tests against a deployed instance of the FastAPI application.\n3.  **Performance Benchmarking**: Automated checks for performance regressions on critical FastAPI endpoints.\n4.  **Security Validation**: Dependency vulnerability scanning and Static Application Security Testing (SAST) for the Python/FastAPI codebase.\nThe ultimate goal is to automatically block merges if any of these validation layers fail, ensuring a robust and secure `main` branch. The framework will be configured to analyze the `src/backend` directory primarily.",
        "testStrategy": "The overall test strategy involves validating each component of the framework individually, then ensuring their integrated operation correctly blocks or permits merges based on the validation outcomes. This will include creating test PRs with deliberate failures (architectural, functional, performance, security) and successes to verify the framework's decision-making.",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Validation Scope and Acceptance Criteria",
            "description": "Document the specific architectural rules, functional requirements, performance benchmarks, and security requirements that will be validated by the framework before any code is written.",
            "dependencies": [],
            "details": "Create a markdown document (e.g., `docs/ci-cd/VALIDATION_CRITERIA.md`) in the repository. It must list: 1) Architectural rules like module boundaries and import restrictions for the `src/backend` structure. 2) Key functional user flows for smoke testing of the FastAPI application. 3) Performance baseline metrics (e.g., API response times, memory usage) for critical FastAPI endpoints. 4) Security requirements and vulnerability thresholds (e.g., OWASP Top 10, dependency vulnerability scanning thresholds). This document will serve as the single source of truth for the validation framework's goals.",
            "status": "pending",
            "testStrategy": "Review the generated document with the lead architect and senior developers to ensure consensus, completeness, and feasibility of the defined criteria."
          },
          {
            "id": 2,
            "title": "Configure CI Pipeline Trigger for 'scientific' Branch Pull Requests",
            "description": "Set up a dedicated CI/CD workflow that triggers automatically when a pull request is opened from the 'scientific' branch to 'main'.",
            "dependencies": [
              1
            ],
            "details": "Create a new GitHub Actions workflow file (`.github/workflows/merge_validation.yml`). Configure it to trigger on pull requests targeting the 'main' branch. This initial version will only define the trigger and placeholder jobs for subsequent validation steps, ensuring it correctly checks out the PR code from the `src/backend` context.",
            "status": "pending",
            "testStrategy": "Create a test pull request from a temporary branch to 'main' and verify that the new CI pipeline is triggered automatically and completes its initial placeholder steps successfully."
          },
          {
            "id": 3,
            "title": "Implement Architectural Consistency Checks",
            "description": "Integrate static analysis tools into the CI pipeline to automatically enforce the architectural rules defined in the scope for the Python/FastAPI application.",
            "dependencies": [
              2
            ],
            "details": "Utilize a tool like `Pylint` (for module import rules), `Adept` (for dependency graph analysis), or a custom Python script leveraging `ast` module parsing to enforce architectural rules defined in `docs/ci-cd/VALIDATION_CRITERIA.md`. This will check module boundaries and import restrictions specific to the `src/backend` structure. Add a new step in the `.github/workflows/merge_validation.yml` CI workflow that runs this analysis. The step must fail the build if any architectural violations are detected, such as a feature module importing from another feature module within `src/backend`.",
            "status": "pending",
            "testStrategy": "Create a test branch with a deliberate architectural violation (e.g., an illegal import statement within `src/backend`). Open a PR and verify that the CI pipeline fails at the static analysis step with a clear, actionable error message highlighting the Python module violation."
          },
          {
            "id": 4,
            "title": "Integrate Full Regression Test Suite Execution",
            "description": "Add a job to the validation pipeline that executes the complete backend test suite (unit and integration tests) to ensure no existing functionality is broken in the FastAPI application.",
            "dependencies": [
              2
            ],
            "details": "Add a new job to the `.github/workflows/merge_validation.yml` file. This job will install all project dependencies (e.g., from `requirements.txt` in the root or `src/backend/requirements.txt`) and then execute the full test suite using `pytest` from the `src/backend` directory. The job must be configured to fail the entire pipeline run if any single test fails. Ensure the test environment is correctly configured with all necessary services (e.g., database, cache) required for the FastAPI application.",
            "status": "pending",
            "testStrategy": "Manually introduce a failing test in a new PR within `src/backend` to ensure the pipeline correctly identifies the failure, reports it, and blocks the merge. Verify that the logs show the complete test suite was executed."
          },
          {
            "id": 5,
            "title": "Develop and Integrate E2E Smoke Tests",
            "description": "Create and run a suite of automated end-to-end (E2E) smoke tests against a live instance of the FastAPI application to verify critical user flows.",
            "dependencies": [
              4
            ],
            "details": "Using `pytest` with `httpx` (or `requests`), write tests that simulate core FastAPI application workflows (e.g., user authentication, data submission, primary resource retrieval) against the `src/backend` service. The CI pipeline will need a step to build a Docker container for the PR's code (e.g., from `src/backend/Dockerfile`), run it, expose the FastAPI application, and then execute these smoke tests against the running container's API.",
            "status": "pending",
            "testStrategy": "Run the smoke tests locally against a developer environment to validate the test logic. Then, trigger the CI pipeline and confirm it correctly builds the container, runs the application, and executes the smoke tests, failing the build if a test fails."
          },
          {
            "id": 6,
            "title": "Implement Automated Performance Benchmark Testing",
            "description": "Create and integrate performance tests for critical FastAPI API endpoints to automatically detect and flag performance regressions.",
            "dependencies": [
              5
            ],
            "details": "Use a tool like `locust` or `pytest-benchmark` within `pytest` to measure key performance indicators (KPIs) like p95 response time for 5-10 critical FastAPI endpoints from `src/backend`. Establish a baseline by running these tests against the 'main' branch. The CI script will compare the PR's performance against this baseline and fail if it exceeds a defined threshold (e.g., 15% degradation). The performance test environment should closely mimic production conditions for the FastAPI service.",
            "status": "pending",
            "testStrategy": "Establish the performance baseline. Then, create a PR with an intentionally inefficient code change (e.g., adding a `time.sleep()` in a hot path within `src/backend`) and verify that the performance test detects the regression, reports the deviation, and fails the pipeline."
          },
          {
            "id": 7,
            "title": "Implement Automated Security Vulnerability Scanning",
            "description": "Integrate automated security scanning tools into the CI pipeline to identify known vulnerabilities in dependencies and potential security weaknesses in the Python/FastAPI application code.",
            "dependencies": [
              2
            ],
            "details": "Add a new job to the `.github/workflows/merge_validation.yml` file. This job will perform two types of scans: 1) Dependency vulnerability scanning using tools like `safety` or `pip-audit` against `requirements.txt` (or similar dependency files in `src/backend`). 2) Static Application Security Testing (SAST) using tools like `Bandit` or `Pylint` with security checks configured, targeting the Python code in `src/backend`. Configure the job to fail the pipeline if critical or high-severity vulnerabilities are found, or if SAST rules are violated.",
            "status": "pending",
            "testStrategy": "Introduce a known vulnerable dependency (e.g., an old version of a common library) or a simple security flaw (e.g., hardcoded credentials) into a test branch in `src/backend`. Verify the CI pipeline correctly identifies and flags these issues, failing the build as appropriate and providing clear output."
          },
          {
            "id": 8,
            "title": "Generate and Publish a Unified Validation Report",
            "description": "Configure the CI pipeline to aggregate results from all validation steps into a single report and publish it as a comment on the pull request.",
            "dependencies": [
              3,
              4,
              6
            ],
            "details": "Use a GitHub Action (like 'actions/github-script') in a final pipeline job to generate a markdown summary of the results. The report should include the status of architectural checks, test suite results (e.g., '1573/1573 passed'), performance benchmark deltas, and security scan findings. This job will post the markdown summary as a comment on the associated PR.",
            "status": "pending",
            "testStrategy": "Trigger the pipeline on a test PR and check that a comment is successfully posted. Verify the comment's content accurately reflects the success or failure of the preceding steps. Check both a fully successful run and a run with a failure."
          },
          {
            "id": 9,
            "title": "Enforce Merge Blocking via Branch Protection Rules",
            "description": "Configure repository branch protection rules to make the merge validation pipeline a required check, preventing merges to 'main' if any validation fails.",
            "dependencies": [
              7
            ],
            "details": "In the GitHub repository settings, navigate to 'Branches' and edit the protection rule for the 'main' branch. Under 'Require status checks to pass before merging', add the merge validation CI job. This will physically disable the merge button on pull requests until the check passes.",
            "status": "pending",
            "testStrategy": "Open a new PR from 'scientific' to 'main' with a change that causes the validation pipeline to fail. Verify that the GitHub UI blocks the merge. Then, push a fix, wait for the pipeline to pass, and confirm the merge button becomes active again."
          }
        ]
      },
      {
        "id": 8,
        "title": "Update Setup Subtree Integration in Scientific Branch",
        "description": "Update the scientific branch to use the new setup subtree methodology that has been implemented in the main branch. This will align the architecture for easier merging and future maintenance, as detailed in the original backlog task: backlog/tasks/alignment/update-setup-subtree-integration.md.",
        "status": "pending",
        "dependencies": [],
        "priority": "high",
        "details": "",
        "testStrategy": "",
        "subtasks": [
          {
            "id": 1,
            "title": "Analyze 'main' branch for setup subtree methodology",
            "description": "Investigate the 'main' branch's Git history and current filesystem to understand the precise implementation details of the 'new setup subtree methodology'. This includes identifying the subtree's remote URL, its local path within the 'main' branch, and the specific `git subtree` commands used for its integration and updates. Pay close attention to any associated scripts or configuration files.",
            "dependencies": [],
            "details": "Use `git log --grep='git subtree'` on the 'main' branch to find relevant commit messages. Examine the `.git/config` file in 'main' for subtree-related entries. Identify the exact path where the subtree is mounted (e.g., 'src/setup' or 'shared/config') and the remote repository it points to. Check for any automation scripts in `scripts/` or `tools/` that manage the subtree.",
            "status": "pending",
            "testStrategy": null
          },
          {
            "id": 2,
            "title": "Identify and isolate target directory in 'scientific' branch",
            "description": "Pinpoint the specific directory or set of files within the 'scientific' branch that corresponds to the 'setup' functionality now managed by the new subtree methodology in 'main'. This content will be replaced or integrated with the subtree.",
            "dependencies": [
              1
            ],
            "details": "Based on the findings from subtask 1 (e.g., if the main branch uses 'src/setup' for the subtree), identify the equivalent directory in the 'scientific' branch. Verify its content aligns with what is expected from the 'setup' component. Create a temporary `temp_backup_scientific_setup` directory.",
            "status": "pending",
            "testStrategy": "Verify the identified directory path and its contents against the expected setup component. Confirm this is the correct target for subtree replacement."
          },
          {
            "id": 3,
            "title": "Backup and remove existing setup code in 'scientific' branch",
            "description": "Before integrating the new setup subtree, create a complete backup of the existing 'setup' related code found in the 'scientific' branch. After backup, safely remove this existing code to ensure a clean slate for the subtree integration and prevent potential conflicts.",
            "dependencies": [
              2
            ],
            "details": "Copy the identified 'setup' directory (e.g., 'src/setup') from the 'scientific' branch to a temporary, version-controlled backup location (e.g., a new branch or a dedicated commit). Then, use `git rm -r <path_to_setup_directory>` to remove the existing directory from the 'scientific' branch's working tree and stage the deletion. Commit these changes.",
            "status": "pending",
            "testStrategy": "After removal, run `git status` to confirm the directory is gone. Attempt to build the project (if applicable) to ensure no immediate, critical build failures due to missing files (expect failures, but ensure it's clean)."
          },
          {
            "id": 4,
            "title": "Integrate the new setup subtree into 'scientific' branch",
            "description": "Add the 'setup' component from its designated remote repository as a `git subtree` into the 'scientific' branch, following the methodology identified in the 'main' branch. This step establishes the official link and pulls in the latest 'setup' code.",
            "dependencies": [
              3
            ],
            "details": "Using the remote URL and path identified in subtask 1, execute the `git subtree add --prefix=<path_in_scientific> <remote_url> <branch_name> --squash` command. For example, `git subtree add --prefix=src/setup https://github.com/org/setup-repo.git main --squash`. Commit the changes after successful addition. If the 'main' branch uses `git subtree pull` from an existing remote, ensure that remote is added first.",
            "status": "pending",
            "testStrategy": "Verify the new directory structure for the subtree appears at the correct path. Check `git log` to confirm the subtree addition commit. Attempt a basic project build to ensure the newly added files are recognized."
          },
          {
            "id": 5,
            "title": "Reconcile 'scientific' branch-specific modifications",
            "description": "Carefully identify and re-apply any unique modifications, configurations, or extensions that were present in the 'scientific' branch's original 'setup' code (backed up in subtask 3) but are not part of the newly integrated subtree. This ensures feature parity for the 'scientific' branch.",
            "dependencies": [
              4
            ],
            "details": "Using the backup created in subtask 3, perform a diff between the backup and the newly integrated subtree content. Manually merge or re-apply any custom logic, configuration changes, or additional files that are specific to the 'scientific' branch's requirements. Resolve any merge conflicts that arise during this process. Commit these reconciliation changes.",
            "status": "pending",
            "testStrategy": "Perform detailed code review of re-applied changes. Run unit tests specific to the 'setup' component, if available, to ensure custom logic behaves as expected. Manually verify configurations are correct."
          },
          {
            "id": 6,
            "title": "Verify and test setup subtree functionality",
            "description": "Thoroughly test the newly integrated setup subtree to ensure all functionalities related to the 'setup' component work correctly within the 'scientific' branch. This includes validating configurations, dependencies, and any interactions with other parts of the system.",
            "dependencies": [
              5
            ],
            "details": "Execute the full suite of unit, integration, and end-to-end tests related to the 'setup' component. If the 'setup' component is responsible for environment configuration or build processes, run full build processes and test environment startup. Pay special attention to areas where 'scientific' branch had specific modifications. Ensure proper loading of configurations and dependencies.",
            "status": "pending",
            "testStrategy": "Run all existing test suites. Develop new integration tests for critical 'setup' functionalities if existing coverage is insufficient. Deploy to a staging environment for full system integration testing to ensure no regressions."
          }
        ]
      },
      {
        "id": 9,
        "title": "Align import-error-corrections Branch with Main Branch",
        "description": "Systematically align feature branch `fix/import-error-corrections` with the main branch. This alignment will carefully preserve the key business logic and unique features of the `fix/import-error-corrections` branch, focusing updates primarily on architectural and common files from the main branch to minimize unnecessary conflicts, while ensuring feature-specific work is maintained. This task is linked to the original backlog item: `backlog/tasks/alignment/task-feature-branch-alignment-import-error-corrections-main.md`.",
        "status": "pending",
        "dependencies": [],
        "priority": "low",
        "details": "",
        "testStrategy": "",
        "subtasks": [
          {
            "id": 1,
            "title": "Ensure clean working directory and checkout feature branch",
            "description": "Before starting the alignment process, ensure there are no uncommitted changes in the local repository and checkout the target feature branch `fix/import-error-corrections`.",
            "dependencies": [],
            "details": "Use `git status` to confirm a clean working directory. If necessary, stash or commit any local changes. Then, execute `git checkout fix/import-error-corrections`.",
            "status": "pending",
            "testStrategy": null
          },
          {
            "id": 2,
            "title": "Update local 'main' branch to latest remote",
            "description": "Synchronize the local 'main' branch with the upstream 'main' branch to ensure the feature branch will be rebased against the most recent changes.",
            "dependencies": [
              1
            ],
            "details": "First, switch to the main branch (`git checkout main`), then fetch and pull the latest changes from the remote (`git pull origin main`).",
            "status": "pending",
            "testStrategy": null
          },
          {
            "id": 3,
            "title": "Run baseline tests on 'fix/import-error-corrections'",
            "description": "Execute the existing test suite on the `fix/import-error-corrections` branch to establish a functional baseline before applying changes from 'main'.",
            "dependencies": [
              2
            ],
            "details": "Switch back to the feature branch (`git checkout fix/import-error-corrections`). Run all relevant unit, integration, and end-to-end tests for the project. Document any existing failures or unexpected behaviors.",
            "status": "pending",
            "testStrategy": "Capture test results (e.g., screenshots of test runner output, log files) to compare against post-rebase results."
          },
          {
            "id": 4,
            "title": "Rebase 'fix/import-error-corrections' onto 'main'",
            "description": "Perform the Git rebase operation to integrate the `main` branch's history into `fix/import-error-corrections`, ensuring a linear commit history.",
            "dependencies": [
              3
            ],
            "details": "While on the `fix/import-error-corrections` branch, execute `git rebase main`. This will apply the commits from the feature branch on top of the latest 'main' commit.",
            "status": "pending",
            "testStrategy": null
          },
          {
            "id": 5,
            "title": "Resolve rebase conflicts",
            "description": "Address and resolve any merge conflicts that arise during the rebase process to ensure code integrity and functionality.",
            "dependencies": [
              4
            ],
            "details": "Upon encountering conflicts, use `git status` to identify conflicting files. Edit these files to resolve conflicts, then stage them (`git add <file>`) and continue the rebase (`git rebase --continue`). Repeat until the rebase is complete.",
            "status": "pending",
            "testStrategy": "Thoroughly review each conflict resolution to ensure correct code merging and no introduction of new bugs."
          },
          {
            "id": 6,
            "title": "Run full test suite post-rebase",
            "description": "After successfully rebasing and resolving conflicts, run the entire project's test suite to verify that no regressions or new issues were introduced.",
            "dependencies": [
              5
            ],
            "details": "Execute all unit, integration, and end-to-end tests on the rebased `fix/import-error-corrections` branch. Compare results with the baseline tests from subtask 3.",
            "status": "pending",
            "testStrategy": "All tests must pass. If any tests fail, debug and fix the issues introduced by the rebase, then re-run tests. Document any new issues."
          },
          {
            "id": 7,
            "title": "Perform local functional validation and code review",
            "description": "Conduct a manual review of the aligned code and perform functional tests specific to the `import-error-corrections` feature to ensure it still works as expected.",
            "dependencies": [
              6
            ],
            "details": "Manually test the `import-error-corrections` functionality. Review the changes introduced from 'main' to ensure they integrate logically with the feature branch's code. Pay attention to any areas that had conflicts.",
            "status": "pending",
            "testStrategy": "Verify the core functionality addressed by `fix/import-error-corrections` still works correctly. Check for unexpected side effects from the `main` branch's changes."
          },
          {
            "id": 8,
            "title": "Force push rebased branch and notify team",
            "description": "Once validation is complete, force push the rebased `fix/import-error-corrections` branch to the remote repository and inform relevant team members.",
            "dependencies": [
              7
            ],
            "details": "Execute `git push --force-with-lease origin fix/import-error-corrections`. Notify the development team, especially those who might be working on or depending on this branch, about the successful rebase and updated remote branch.",
            "status": "pending",
            "testStrategy": null
          }
        ]
      },
      {
        "id": 10,
        "title": "Improve Task Management with Advanced Testing Integration",
        "description": "Enhance the Task Master system with advanced testing integration capabilities, including automated testing validation in task completion workflows, branch-specific task tracking and validation, incorporation of scientific branch testing frameworks, and testing requirement enforcement in task creation.",
        "details": "This task focuses on deeply integrating testing and validation processes into our task management and CI/CD pipelines, building upon the foundational 'Comprehensive Merge Validation Framework' established in Task 7. The goal is to enforce quality and consistency from task creation through to completion.\n\n1.  **Automated Testing Validation into Task Completion Workflow:** Enhance existing GitHub Actions workflows (as defined in Task 7 for `scientific` to `main` merges) to automatically validate test results upon pull request merges or task completion markers. This includes integrating coverage checks, static analysis results, and functional test suite outcomes directly into the task status reporting (e.g., via GitHub status checks or a custom webhook to a task tracking system).\n2.  **Adding Branch-Specific Task Tracking and Validation:** Implement mechanisms to differentiate validation rules and required checks based on the target branch (e.g., `main`, `scientific`, feature branches). This could involve conditional GitHub Actions workflows or specific branch protection rules that vary per branch type, ensuring that `scientific` branch merges, for instance, trigger specific 'scientific branch testing frameworks'.\n3.  **Incorporate Scientific Branch Testing Frameworks:** Develop and integrate specialized testing frameworks for the `scientific` branch within the CI/CD pipeline. This may involve setting up dedicated test environments, using specialized data sets for model validation, or incorporating statistical testing and reproducibility checks tailored for scientific computing or AI model evaluation within `src/backend`'s AI components. Leverage existing Python testing frameworks like `pytest` and extend them with custom plugins or reporting.\n4.  **Add Testing Requirement Enforcement in Task Creation:** Implement checks at the pull request creation or task definition stage to ensure testing requirements are met. This could include:\n    *   Pre-commit hooks or GitHub Actions checks requiring new or modified test files (`tests/`) to be present for new features/bug fixes.\n    *   Mandating minimum test coverage thresholds (e.g., via `pytest-cov` and reporting to Codecov/Coveralls) for affected modules in `src/backend` before a PR can be merged.\n    *   Enforcing specific labels or comments in PR descriptions that confirm testing strategy has been addressed.\n\nAll integrations should leverage existing GitHub and Python ecosystem tools where possible to minimize overhead, and refer to `src/backend` for all code-related implementations.",
        "testStrategy": "A multi-faceted test strategy will be employed to ensure the robust implementation of advanced testing integrations:\n1.  **Unit and Integration Tests:** Develop comprehensive unit tests for any new scripts or code that facilitate these integrations (e.g., custom GitHub Actions, webhook handlers).\n2.  **End-to-End Workflow Tests:** Create specific test scenarios for each integration point:\n    *   **Task Completion Validation:** Create a feature branch, add code, add tests (passing and failing), open a PR, and observe how the CI/CD pipeline (leveraging Task 7's framework) validates and reports task status upon merge attempts.\n    *   **Branch-Specific Validation:** Test PRs targeting `main` vs. `scientific` to ensure different sets of required checks or workflows are correctly triggered and enforced.\n    *   **Scientific Framework Integration:** Run PRs with changes to scientific components (e.g., in `src/backend/ai_engine`) and verify that the specialized scientific testing frameworks execute correctly and report results. This includes testing with expected data variations.\n    *   **Requirement Enforcement:** Attempt to create PRs that intentionally violate testing requirements (e.g., no new tests for new features, low coverage) and confirm that the enforcement mechanisms (CI checks, pre-commit) correctly block the PR or flag the issue.\n3.  **Regression Testing:** Ensure that these new integrations do not adversely affect existing CI/CD pipelines or merge validation processes defined in Task 7.\n4.  **Documentation & User Acceptance:** Verify that the new requirements and workflows are clearly documented and understandable for developers, and conduct internal UAT to confirm usability and effectiveness.",
        "status": "pending",
        "dependencies": [
          7
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Automated testing validation into task completion workflow",
            "description": "Integrate automated testing validation into the task completion workflow to ensure tasks cannot be marked complete without proper testing validation.",
            "details": "",
            "status": "completed",
            "dependencies": [],
            "parentTaskId": 10
          },
          {
            "id": 2,
            "title": "Adding branch-specific task tracking and validation",
            "description": "Implement branch-aware validation rules in CI/CD service with conditional branch-specific testing for scientific vs standard branches, and task-branch association validation.",
            "details": "",
            "status": "completed",
            "dependencies": [],
            "parentTaskId": 10
          },
          {
            "id": 3,
            "title": "Incorporate scientific branch testing frameworks into Task Master",
            "description": "Integrate the advanced testing frameworks and practices from the scientific branch into the Task Master system, including enhanced test coverage requirements, scientific-specific test suites, and advanced testing methodologies.",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 10
          },
          {
            "id": 4,
            "title": "Add testing requirement enforcement in task creation",
            "description": "Implement validation rules during task creation to ensure that tasks include appropriate testing requirements, acceptance criteria, and testing strategies based on their complexity and branch context.",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 10
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-11-06T04:11:47.735Z",
      "updated": "2025-11-06T06:37:46.528Z",
      "description": "Tasks for master context"
    }
  },
  "backend": {
    "tasks": [],
    "metadata": {
      "created": "2025-11-06T04:58:29.416Z",
      "updated": "2025-11-06T04:58:29.416Z",
      "description": "Backend-related tasks including recovery, migration, and refactoring"
    }
  },
  "security": {
    "tasks": [],
    "metadata": {
      "created": "2025-11-06T04:58:32.191Z",
      "updated": "2025-11-06T04:58:32.191Z",
      "description": "Security enhancement tasks including RBAC, MFA, and auditing"
    }
  },
  "alignment": {
    "tasks": [
      {
        "id": 1,
        "title": "Recover Lost Backend Modules and Features",
        "description": "Investigate the Git history to find, recover, and reintegrate backend modules and features that were lost during recent commits and merges. This is a prerequisite to ensure the subsequent migration and refactoring work is performed on a complete and correct codebase.",
        "details": "Begin by creating a comprehensive list of expected features and modules based on the PRD and any existing design documents. Use Git commands to audit the repository's history for lost code. Key commands include `git reflog` to find dangling commits, `git log --diff-filter=D --summary` to find deleted files, and `git log -S'<unique_code_string>'` to search for code that has disappeared. Once found, use `git checkout <commit_hash> -- <file_path>` or `git cherry-pick <commit_id>` to restore the code into a dedicated recovery branch. All recovered code must be documented in a new file, e.g., `docs/recovery_log.md`.",
        "testStrategy": "Create a new branch for recovery. After restoring files/code, run the existing test suite to check for immediate breakages. For any recovered feature that lacks test coverage, write minimal unit or integration tests to confirm its basic functionality is restored. The primary goal is to reintegrate the code and ensure the application remains stable. A peer review of the recovered code against the recovery log is mandatory before merging.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Recovery Branch and Compile Lost Feature Checklist",
            "description": "Prepare the workspace for code recovery by creating a new Git branch. Review `docs/PRD.md` to create a comprehensive checklist of all features and modules that are expected to be present in the backend.",
            "dependencies": [],
            "details": "Create a new branch named `feature/recover-lost-modules`. Create a new file `docs/recovery_log.md` and populate it with a 'Lost Features Checklist' section based on the analysis of `docs/PRD.md`, including 'Smart Filtering Engine', 'Smart Retrieval Engine', and 'Email Summarization AI'.",
            "status": "done",
            "testStrategy": "N/A - This is a preparatory task. Verification will be done by checking for the existence and content of the new branch and the `docs/recovery_log.md` file."
          },
          {
            "id": 2,
            "title": "Audit Git History to Identify Commits Containing Lost Modules",
            "description": "Use Git forensics commands to search the repository's history for commits related to the lost features identified in the checklist. Document the findings in the recovery log.",
            "dependencies": [
              1
            ],
            "details": "Use commands like `git log --diff-filter=D --summary`, `git log -S'SmartFilteringEngine'`, `git log -S'SmartRetrievalEngine'`, and `git reflog` to find commits where files like `smart_filters.py` and `smart_retrieval.py` were deleted or last existed. Record the relevant commit hashes and file paths in `docs/recovery_log.md`.",
            "status": "done",
            "testStrategy": "Verification involves reviewing the `docs/recovery_log.md` file to ensure it contains a list of commit hashes and file paths that verifiably contain the lost code when inspected with `git show <commit_hash>:<file_path>`."
          },
          {
            "id": 3,
            "title": "Restore Core AI Modules: 'smart_filters' and 'smart_retrieval'",
            "description": "Restore the `smart_filters.py` and `smart_retrieval.py` modules from the commits identified during the Git audit into the recovery branch.",
            "dependencies": [
              2
            ],
            "details": "Using the commit hashes documented in `docs/recovery_log.md`, execute `git checkout <commit_hash> -- <path/to/file>` for both `smart_filters.py` and `smart_retrieval.py` to restore them to the `backend/` directory (or their original location).",
            "status": "done",
            "testStrategy": "After checkout, verify the files `backend/smart_filters.py` and `backend/smart_retrieval.py` exist in the working directory and are not empty. Run the application to ensure it does not immediately crash due to syntax errors in the restored files."
          },
          {
            "id": 4,
            "title": "Restore Additional Lost Modules (e.g., Email Summarization)",
            "description": "Restore any other identified lost modules, such as the email summarization feature and related utility functions, using the same Git recovery process.",
            "dependencies": [
              2
            ],
            "details": "Based on the git audit, restore other missing files, such as a module for the 'Email Summarization AI' (e.g., `backend/summarizer.py`) and any helper utilities they depended on. Use `git checkout <commit_hash> -- <path/to/file>` and update `docs/recovery_log.md` with the status of each restored item.",
            "status": "done",
            "testStrategy": "Verify that the additional restored files (e.g., `backend/summarizer.py`) exist in the working directory. Check file contents to ensure they are not empty and appear to be complete."
          },
          {
            "id": 5,
            "title": "Integrate and Verify All Recovered Backend Modules",
            "description": "Ensure all restored modules are correctly integrated into the application. This includes fixing imports, running existing tests, and adding minimal new tests for uncovered restored code to confirm basic functionality.",
            "dependencies": [
              3,
              4
            ],
            "details": "Update `backend/main.py` and other necessary files to import and wire up endpoints for the restored modules. Execute the full existing test suite (`pytest tests/`). If restored features like `smart_filters` lack tests, add a new test file (e.g., `tests/test_smart_filters.py`) with a single test case to confirm a basic function call succeeds.",
            "status": "done",
            "testStrategy": "The primary goal is successful integration. All existing tests must pass. Any new minimal tests for recovered features must also pass. A final manual check via `uvicorn backend.main:app` should show the application starts without errors."
          }
        ]
      },
      {
        "id": 2,
        "title": "Backend Migration from 'backend' to 'src/backend'",
        "description": "Execute the complete structural migration of the legacy 'backend' package to the new modular architecture under 'src/backend'. This is a critical architectural improvement to modernize the codebase and enable further development.",
         "details": "1. Create a new branch from the scientific branch (which contains the most advanced backend implementation with 20+ modules, AI/NLP features, security enhancements, and comprehensive testing). 2. Physically move the entire `backend` directory into `src/` and rename it to `src/backend`. 3. Perform a project-wide find-and-replace to update all Python import statements from `from backend...` to `from src.backend...`. Use a tool like `sed`, `grep`, or an IDE's refactoring capabilities. 4. Update any configuration files that reference the old path. This includes `PYTHONPATH` definitions in Dockerfiles (`ENV PYTHONPATH=\"/app/src:$PYTHONPATH\"`), `docker-compose.yml`, CI/CD pipeline scripts (e.g., `.github/workflows/ci.yml`), and potentially `pyproject.toml` if using editable installs. 5. After all tests pass, delete the original top-level `backend` directory. 6. Ensure `src/__init__.py` and `src/backend/__init__.py` exist to make them valid packages.",
        "testStrategy": "The primary validation method is comprehensive regression testing. Run the full existing test suite and ensure 100% of tests pass. Perform a manual smoke test of the application by starting it and hitting key API endpoints using Postman or cURL to confirm it is fully functional. The application's behavior must be identical to the pre-migration state. No new feature tests are required for this task.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create feature branch for backend migration",
            "description": "Create a new dedicated Git branch from the main development branch (or 'scientific' as per context) to isolate changes for the backend migration. This ensures that Task 1 (code recovery) is merged and stable before starting.",
            "dependencies": [
              1
            ],
            "details": "Confirm that Task 1 (Recover Lost Backend Modules and Features) is fully merged into the base branch (e.g., 'scientific'). Then, create a new branch using `git checkout scientific && git pull && git checkout -b feature/backend-to-src-migration`.",
            "status": "pending",
            "testStrategy": null
          },
          {
            "id": 2,
            "title": "Move 'backend' directory to 'src/backend' and ensure package structure",
            "description": "Physically relocate the entire 'backend' directory into the 'src/' directory and rename it to 'src/backend'. Additionally, verify or create `__init__.py` files within `src/` and `src/backend/` to ensure they are recognized as Python packages.",
            "dependencies": [
              1
            ],
            "details": "Execute shell commands: `mkdir -p src` followed by `mv backend src/backend`. Then, verify the existence of `src/__init__.py` and `src/backend/__init__.py`. If not present, create empty files using `touch src/__init__.py` and `touch src/backend/__init__.py`.",
            "status": "pending",
            "testStrategy": "Verify directory structure with `ls src/backend` and `ls src/__init__.py`."
          },
          {
            "id": 3,
            "title": "Refactor all Python import statements",
            "description": "Perform a comprehensive project-wide find-and-replace operation to update all Python import statements that refer to the old `backend` package structure to the new `src.backend` package structure.",
            "dependencies": [
              2
            ],
            "details": "Use an IDE's refactoring tools or command-line utilities (e.g., `grep -rl 'from backend' . | xargs sed -i 's/from backend/from src.backend/g'` and similar for `import backend`) to change all instances of `from backend...` to `from src.backend...` and `import backend.module` to `import src.backend.module`. Carefully review all modified files.",
            "status": "pending",
            "testStrategy": "Run a static analysis tool (e.g., flake8, pylint) to catch immediate import errors. Attempt to run the application to see if it starts without import-related crashes. The full test suite will provide comprehensive validation."
          },
          {
            "id": 4,
            "title": "Update project configuration files and environment variables",
            "description": "Modify all relevant configuration files and environment variable definitions (e.g., `PYTHONPATH` in Dockerfiles, `docker-compose.yml`, CI/CD scripts, `pyproject.toml`) to reflect the new `src/backend` path instead of the old `backend` path.",
            "dependencies": [
              3
            ],
            "details": "Search for and update references to `backend` in: Dockerfiles (`ENV PYTHONPATH=/app/src:$PYTHONPATH`), `docker-compose.yml` (e.g., volume mounts, build contexts), `.github/workflows/ci.yml` (e.g., test commands, working directories), and `pyproject.toml` (e.g., `packages` array if present).",
            "status": "pending",
            "testStrategy": "Execute Docker builds and container runs. Trigger CI/CD pipeline runs for the branch to ensure all automated steps (build, test, lint) pass without configuration-related errors. Manually inspect environment variables in running containers."
          },
          {
            "id": 5,
            "title": "Execute full test suite and perform application smoke test",
            "description": "Run the entire existing automated test suite to rigorously verify that the migration has not introduced any regressions. After successful automated tests, perform a manual smoke test of the application to confirm basic functionality.",
            "dependencies": [
              4
            ],
            "details": "Run all unit, integration, and end-to-end tests (e.g., `pytest`). After tests pass, start the FastAPI application locally (e.g., `uvicorn src.backend.main:app --reload`) and use tools like Postman or cURL to hit critical API endpoints (e.g., `/health`, authentication, a few core business logic endpoints) to ensure the application is functional.",
            "status": "pending",
            "testStrategy": "The full automated test suite must pass with 100% success. Manual smoke test checklist includes: application startup without errors, successful authentication, and execution of at least 3-5 critical API endpoints. Verify database interactions if applicable."
          },
          {
            "id": 6,
            "title": "Delete original top-level 'backend' directory",
            "description": "Once all automated tests have passed and manual smoke testing confirms the application is fully functional with the new structure, safely remove the original, now obsolete, top-level 'backend' directory.",
            "dependencies": [
              5
            ],
            "details": "After absolute confidence in the successful migration and validated functionality, execute `rm -rf backend` from the project root.",
            "status": "pending",
            "testStrategy": "Verify that the `backend` directory no longer exists using `ls -d backend`. As a final check, re-run a small set of critical tests or a quick smoke test to confirm no unexpected dependencies on the deleted directory existed (e.g., hidden relative imports)."
          }
        ]
      },
      {
        "id": 3,
        "title": "Implement Enhanced Security: RBAC, MFA, Session Management, and Auditing",
        "description": "Upgrade the existing JWT-based authentication system to include Role-Based Access Control (RBAC), Multi-Factor Authentication (MFA), secure session management, and audit logging for sensitive operations, following modern security best practices.",
        "details": "This task will be implemented on the new `src/backend` structure. 1. **RBAC**: Extend the User model/schema with a `role: str` field. Create a FastAPI dependency that checks roles. Example: `def require_role(required_roles: list[str]): def dependency(current_user: User = Depends(get_current_user)): if current_user.role not in required_roles: raise HTTPException(403); return current_user; return dependency`. Protect routes with `Depends(require_role(['admin']))`. 2. **MFA**: Integrate `pyotp~=2.9.0`. Add `mfa_secret: str` and `mfa_enabled: bool` to the User model. Create endpoints: `POST /auth/mfa/generate` (returns a `pyotp.totp.TOTP(...).provisioning_uri(...)`) and `POST /auth/mfa/verify` (checks code). Update the login flow to require a second step if MFA is enabled. 3. **Session Management**: Use `redis-py~=5.0.1`. On login, store a session token in Redis with a TTL (e.g., 1h). The JWT issued to the client can be short-lived (e.g., 15m). A middleware will validate the session token against Redis on each request, allowing for immediate session revocation. 4. **Audit Logging**: Use Python's `logging` module to create a dedicated 'audit' logger. Create a middleware or decorator to apply to sensitive endpoints. The log should capture `timestamp`, `user_id`, `source_ip`, `action`, and `outcome` in a structured format (JSON is recommended).",
        "testStrategy": "Develop unit tests for each new security feature. For RBAC, test that users with incorrect roles are denied access (403). For MFA, test the TOTP generation and validation logic. For Session Management, test session expiry and revocation. For Audit Logging, verify that sensitive actions are logged correctly to the specified output. Create integration tests that simulate a full login flow with MFA and subsequent access to a role-protected endpoint.",
        "priority": "high",
        "dependencies": [
          2
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "Refactor High-Complexity Modules and Duplicated Code",
        "description": "Improve code quality by refactoring large modules (`smart_filters.py`, `smart_retrieval.py`), reducing code duplication in AI engine modules, and simplifying high-complexity functions as identified in the PRD, applying research-backed refactoring best practices.",
        "status": "pending",
        "dependencies": [
          2
        ],
        "priority": "medium",
        "details": "This refactoring will be performed on the new `src/backend` structure, incorporating modern refactoring best practices and an incremental, test-driven approach.\n\n1.  **Module Splitting & Incremental Refactoring for `smart_filters.py` and `smart_retrieval.py`**:\n    *   **Goal**: Decompose these large, monolithic modules (`src/backend/smart_filters.py` at 1598 lines and `src/backend/smart_retrieval.py` at 1198 lines) into smaller, more cohesive, and single-responsibility modules, strictly adhering to the Single Responsibility Principle (SRP) and aiming for high cohesion and low coupling.\n    *   **Strategy**: Employ a phased 'Extract Module' or 'Extract Class' refactoring pattern. For each large module:\n        *   **Identify Cohesive Units**: Systematically analyze the existing files to identify distinct logical concerns, architectural layers, or sets of closely related functions/data that exhibit 'Feature Envy' (methods using data from other objects more than their own) or form 'Data Clumps'. These are prime candidates for extraction.\n        *   **Create Dedicated Packages**: Create a dedicated package directory, e.g., `src/backend/smart_filters/` and `src/backend/smart_retrieval/`. This clearly delineates the new module boundaries.\n        *   **Module Breakdown Examples**:\n            *   `smart_filters.py`: Potential modules include `rule_parsers.py` (for parsing rule definitions from configuration, e.g., `src/backend/smart_filters/rule_parsers.py`), `filter_evaluators.py` (for applying filter logic), `data_transformers.py` (for preparing data for filtering), `persistence.py` (for loading/saving filter configurations).\n            *   `smart_retrieval.py`: Potential modules include `query_builders.py` (for constructing retrieval queries), `ranking_algorithms.py` (for scoring and ordering results), `source_integrations.py` (for interfacing with data sources, potentially using 'Ports and Adapters' pattern), `result_processors.py` (for post-processing retrieved items).\n        *   **Incremental Steps**: For each identified concern, move the related functions, classes, and their associated data into a new, dedicated Python file within its respective package directory. Update all internal and external imports to reflect the new structure. Each extraction should be a small, self-contained, and testable commit.\n        *   **Public API Control**: Utilize `__init__.py` within these new packages to define and control the public API, exposing only necessary functions/classes to avoid tightly coupling consumers to internal module structures (e.g., using `from .sub_module import func_name` in `__init__.py` to expose `func_name` at the package level).\n\n2.  **Reduce Code Duplication in AI Engine**:\n    *   **Goal**: Eliminate the 165-195 reported duplication occurrences across the AI engine modules (e.g., `src/backend/ai/email_filter_node.py` and other related AI components), adhering to the Don't Repeat Yourself (DRY) principle.\n    *   **Strategy**: Identify recurring code blocks, patterns, and boilerplate. Apply 'Extract Method', 'Extract Class', or 'Extract Superclass' refactorings to abstract common logic into shared, reusable utility functions and classes.\n    *   **Location**: Create a new module `src/backend/ai/utils.py` for general AI-related helper functions specific to the AI domain. For broader, cross-cutting utilities (e.g., data validation, common error handling), consider `src/backend/utils/common.py`.\n    *   **Examples of Abstraction**: Look for repeated data validation logic (e.g., using Pydantic models for input validation), common pre-processing steps for text/email content (e.g., tokenization, normalization), standardized error handling patterns, logging boilerplate, or shared data access patterns. Prioritize creating small, pure functions where inputs map deterministically to outputs, making them easily testable and reusable.\n\n3.  **Function Simplification (`setup_dependencies`, `migrate_sqlite_to_json`, `run`)**:\n    *   **Goal**: Significantly reduce the cyclomatic complexity of `setup_dependencies` (complexity 21, likely found in `src/backend/dependencies.py`), `migrate_sqlite_to_json` (complexity 17, likely in `src/backend/utils/database.py`), and the `run` method in `src/backend/ai/email_filter_node.py` (complexity 16), improving readability and maintainability.\n    *   **Strategy**: Apply the 'Extract Method' refactoring pattern incrementally. Break down these large functions into smaller, private helper functions (conventionally prefixed with `_`) that each encapsulate a single, distinct responsibility or logical step. Consider breaking down based on:\n        *   **Sequence of Operations**: Separate distinct sequential steps.\n        *   **Decision Points**: Extract complex conditional logic into its own method.\n        *   **Loop Processing**: Encapsulate the body of a loop or its initialization/finalization.\n    *   **Specifics**:\n        *   `setup_dependencies` (in `src/backend/dependencies.py`): Extract initialization steps into private methods like `_initialize_database_connection()`, `_load_application_config()`, `_setup_logging()`, `_register_event_handlers()`, etc.\n        *   `migrate_sqlite_to_json` (in `src/backend/utils/database.py`): Decompose into steps such as `_read_data_from_sqlite(db_path)`, `_transform_row_to_json_record(row)`, `_write_json_records_to_file(records, output_path)`.\n        *   `run` (in `src/backend/ai/email_filter_node.py`): Identify distinct phases of its execution lifecycle, such as `_ingest_email_messages()`, `_preprocess_message(message)`, `_apply_ai_filters(processed_message)`, `_collate_results(filter_results)`, `_store_or_dispatch_results(final_results)`. Each phase should become a separate, focused private method.\n    *   **Naming**: Ensure extracted methods have descriptive names that clearly convey their purpose and avoid generic names. If a function has too many parameters after extraction, consider 'Introduce Parameter Object' refactoring.\n\n4.  **Continuous Integration with Refactoring**: Throughout this task, maintain small, atomic commits for each refactoring step, ensuring that the system remains in a working state after every commit. This facilitates easy rollback and debugging.",
        "testStrategy": "This is a pure refactoring task; no new functionality should be introduced, and the external behavior of the system must remain unchanged. A robust test-driven refactoring strategy will be employed:\n1.  **Pre-refactoring Characterization Tests (Golden Master)**: Before initiating any changes, ensure all target modules (`src/backend/smart_filters.py`, `src/backend/smart_retrieval.py`, `src/backend/ai/email_filter_node.py`, `src/backend/dependencies.py`, `src/backend/utils/database.py`, and any relevant AI engine modules) have comprehensive test coverage. If coverage is lacking, write 'characterization tests' (also known as 'golden master tests') to rigorously capture and lock in the current observable behavior, even if it's imperfect. These tests are critical to ensure functional equivalence post-refactoring.\n2.  **Incremental Testing and Verification**: After *each small, atomic refactoring step* (e.g., extracting a single method, moving a set of functions to a new module, changing an import), immediately run the relevant test suite (including characterization tests) to catch regressions early. This iterative testing approach is fundamental to safe and effective refactoring. The goal is to always have a green test suite.\n3.  **Behavioral Preservation**: All existing tests for the modified code must pass without any alterations to the tests themselves. The external behavior of the system should remain unchanged. New tests should only be added to cover newly extracted units or to improve coverage where it was initially insufficient for safe refactoring.\n4.  **Static Analysis Integration and Monitoring**: \n    *   **Baseline**: Run a static analysis tool like `radon` (`radon cc -a .` for cyclomatic complexity and `radon mi -a .` for maintainability index) across the codebase (or targeted modules) *before* starting the refactoring to establish a quantitative baseline for complexity and maintainability.\n    *   **Continuous Monitoring**: Integrate these checks into a pre-commit hook or CI/CD pipeline if possible. Alternatively, run them regularly during the refactoring process to monitor progress, ensuring complexity metrics decrease and maintainability indices improve. Tools like `pylint` and `flake8` should also be run to enforce coding standards and identify potential issues.\n    *   **Post-refactoring Verification**: Re-run `radon`, `pylint`, and `flake8` after the refactoring is complete to quantify the reduction in cyclomatic complexity, confirm improved maintainability, and verify adherence to coding standards, thereby proving the task's success.\n5.  **Performance Check**: Conduct basic performance smoke tests or run existing benchmarks to ensure that the refactoring has not introduced any significant performance degradations, especially in critical paths involving the AI engine or data processing. Tools like `cProfile` can be used for targeted analysis if needed.",
        "subtasks": null
      },
      {
        "id": 5,
        "title": "Align Feature Branches with Scientific Branch",
        "description": "Systematically align multiple feature branches with the scientific branch to ensure code consistency, reduce future merge conflicts, and propagate the latest changes. This process will carefully preserve the key business logic and unique features of each feature branch, focusing updates primarily on architectural and common files from the scientific branch to minimize unnecessary conflicts, while ensuring feature-specific work is maintained.",
        "status": "pending",
        "dependencies": [
          1,
          2,
          3,
          4
        ],
        "priority": "high",
        "details": "This high-priority task involves a coordinated effort to bring all active feature branches up-to-date with the stable 'scientific' branch. The process will be executed in three main parts.\n\nPart 1: Feature Branch Assessment\n- Use `git branch --remote` and `git log` to identify all active branches diverging from 'scientific'.\n- Create a shared checklist (e.g., a repository markdown file) of branches to be aligned, including: feature/backlog-ac-updates, fix/import-error-corrections, docs-cleanup, feature/search-in-category, feature/merge-clean, feature/merge-setup-improvements.\n- Prioritize the branches based on importance and complexity of divergence.\n\nPart 2: Alignment Execution\n- For each branch, create a local backup first (e.g., `git branch <branch-name>-backup-pre-align`).\n- Check out the feature branch (`git checkout <feature-branch>`).\n- For public or shared branches, use a merge strategy to preserve history: `git merge scientific`.\n- Systematically resolve any merge conflicts, using visual merge tools for clarity. Document complex resolutions in the merge commit message.\n\nPart 3: Validation and Documentation\n- After each successful alignment, push the updated branch to the remote repository.\n- Create a Pull Request for each aligned branch to allow for code review and automated CI checks.\n- Update the central alignment checklist to reflect the status of each branch.",
        "testStrategy": "Validation will focus on ensuring no regressions are introduced during the alignment process.\n1. Before beginning alignment on a branch, run its existing test suite to establish a baseline.\n2. After the merge/rebase is completed and all conflicts are resolved locally, run the full project test suite. All tests must pass.\n3. Perform a manual smoke test on the core functionality provided by the feature branch to ensure it has not been broken by the merge.\n4. Upon pushing the aligned branch and opening a PR, the continuous integration (CI) pipeline must pass all checks, including linting, unit tests, and integration tests. This CI pass is a mandatory success criterion for each branch.",
        "subtasks": [
          {
            "id": 1,
            "title": "Identify Divergent Branches and Create Alignment Plan",
            "description": "Analyze all remote feature branches to identify which have diverged from the 'scientific' branch. Document these branches in a new markdown file to serve as a master checklist for the alignment process.",
            "dependencies": [],
            "details": "Use 'git branch --remote' and 'git log' to compare each feature branch with 'scientific'. Create a new file named `ALIGNMENT_CHECKLIST.md` in the project root. List the branches to be aligned, including `feature/backlog-ac-updates`, `fix/import-error-corrections`, `docs-cleanup`, `feature/search-in-category`, `feature/merge-clean`, and `feature/merge-setup-improvements`. Add columns for status and notes.",
            "status": "pending",
            "testStrategy": "Verify the generated `ALIGNMENT_CHECKLIST.md` file is present in the repository and accurately lists all the feature branches mentioned in the task description."
          },
          {
            "id": 2,
            "title": "Create Local Backups of All Targeted Feature Branches",
            "description": "Before initiating any merge operations, create local backup copies of all feature branches listed in the alignment checklist. This provides a critical safety net and a simple rollback point.",
            "dependencies": [
              1
            ],
            "details": "For each branch identified in `ALIGNMENT_CHECKLIST.md`, execute the command `git branch <branch-name>-backup-pre-align`. For example, for 'feature/backlog-ac-updates', run `git branch feature/backlog-ac-updates-backup-pre-align`. Verify backup creation with `git branch`.",
            "status": "pending",
            "testStrategy": "Run `git branch | grep -- '-backup-pre-align'` locally to confirm that a backup has been created for every branch listed in the alignment checklist."
          },
          {
            "id": 3,
            "title": "Align 'feature/backlog-ac-updates' with 'scientific' Branch",
            "description": "Perform a merge of the 'scientific' branch into the 'feature/backlog-ac-updates' branch. This will propagate the latest stable changes into the feature branch.",
            "dependencies": [
              2
            ],
            "details": "First, checkout the feature branch using `git checkout feature/backlog-ac-updates`. Then, run `git merge scientific`. Systematically resolve any merge conflicts that arise using a visual merge tool and document complex resolutions in the merge commit message.",
            "status": "pending",
            "testStrategy": "Run the project's test suite on the branch before the merge to establish a baseline. After the merge and conflict resolution, run the full test suite again to ensure no regressions have been introduced."
          },
          {
            "id": 4,
            "title": "Align 'fix/import-error-corrections' with 'scientific' Branch",
            "description": "Perform a merge of the 'scientific' branch into the 'fix/import-error-corrections' branch to ensure the fix is compatible with the latest codebase.",
            "dependencies": [
              2
            ],
            "details": "Checkout the fix branch using `git checkout fix/import-error-corrections`. Execute `git merge scientific`. Carefully resolve any merge conflicts, paying special attention to file path and import statement changes given the nature of this branch.",
            "status": "pending",
            "testStrategy": "Before merging, run tests to confirm the fix works as intended. After merging, run the full test suite, especially integration tests that might fail due to incorrect module paths or circular dependencies."
          },
          {
            "id": 5,
            "title": "Align 'feature/search-in-category' with 'scientific' Branch",
            "description": "Merge the latest changes from the 'scientific' branch into the 'feature/search-in-category' branch, resolving any resulting conflicts.",
            "dependencies": [
              2
            ],
            "details": "Switch to the feature branch with `git checkout feature/search-in-category`. Run `git merge scientific` to start the alignment. Resolve all merge conflicts and ensure the new search functionality integrates correctly with the latest base code from 'scientific'.",
            "status": "pending",
            "testStrategy": "Run existing tests on the branch to get a baseline. After the merge, run the full test suite. Additionally, perform a manual smoke test of the search-in-category feature to confirm its behavior remains correct."
          },
          {
            "id": 6,
            "title": "Align Remaining Minor Branches with 'scientific'",
            "description": "Perform the alignment process for the remaining, lower-priority branches: 'docs-cleanup', 'feature/merge-clean', and 'feature/merge-setup-improvements'.",
            "dependencies": [
              2
            ],
            "details": "Sequentially process each branch. For each one, use `git checkout <branch-name>`, then `git merge scientific`. Resolve any conflicts that may arise. Given their scope, these branches are expected to have fewer conflicts.",
            "status": "pending",
            "testStrategy": "For 'docs-cleanup', a visual inspection of rendered documentation changes is sufficient. For 'feature/merge-clean' and 'feature/merge-setup-improvements', the full project test suite must be run post-merge to validate integrity."
          },
          {
            "id": 7,
            "title": "Push Aligned Branches and Create Pull Requests",
            "description": "Push all the locally merged and validated feature branches to the remote repository. Create a corresponding Pull Request for each aligned branch to enable code review and trigger CI/CD pipelines.",
            "dependencies": [
              3,
              4,
              5,
              6
            ],
            "details": "For each successfully aligned branch, run `git push origin <branch-name> --force-with-lease` if rebase was used, or `git push` if merge was used. Subsequently, navigate to the repository's web UI and create a Pull Request for each branch, targeting 'scientific'.",
            "status": "pending",
            "testStrategy": "Confirm that a new Pull Request exists for each aligned branch. Check that the PR's 'Files changed' tab correctly reflects the merge from 'scientific' and that CI checks have been automatically triggered."
          },
          {
            "id": 8,
            "title": "Final Validation, Review, and Checklist Completion",
            "description": "Monitor the CI pipelines for all created Pull Requests, address any feedback from code reviews, and update the master checklist to reflect the completion of each branch alignment.",
            "dependencies": [
              1,
              7
            ],
            "details": "Review the CI build logs for each PR to ensure all tests pass. Address any code review comments by pushing new commits to the respective branches. After a PR is fully validated and approved, update its status to 'Completed' in the `ALIGNMENT_CHECKLIST.md` file.",
            "status": "pending",
            "testStrategy": "Final validation is successful when all created PRs have a 'green' build status, have been approved by at least one reviewer, and the `ALIGNMENT_CHECKLIST.md` file is updated to show all branches as 'Completed'."
          }
        ]
      },
      {
        "id": 6,
        "title": "Deep Integration & Refactoring: Align feature-notmuch-tagging-1 with Scientific, Enhance Data Platform, and Introduce Scalable AI Capabilities",
        "description": "Execute a comprehensive alignment of the `feature-notmuch-tagging-1` branch with the `scientific` branch, focusing on robust integration of the enhanced NotmuchDataSource, AI analysis, smart tagging, and full CRUD operations. This task not only involves updating architectural and common files from the `scientific` branch but also requires significant refactoring to ensure scalability, fault tolerance, and deep compatibility with existing data structures and the analytics ecosystem, while preserving and optimizing the feature branch's distinct functionalities. Special attention should be paid to data model evolution, performance under load, and comprehensive security hardening.",
        "status": "pending",
        "dependencies": [
          1,
          2,
          3,
          4
        ],
        "priority": "high",
        "details": "This task involves a multi-faceted integration, including architectural adjustments and new feature development:\n1.  **Strategic Branch Alignment & Conflict Resolution:** Initiate by rebasing `feature-notmuch-tagging-1` onto the latest `scientific` branch. Resolve all merge conflicts meticulously, especially in core data access and AI-related modules, ensuring `scientific`'s foundational stability while integrating feature-specific changes. Document all non-trivial conflict resolutions.\n2.  **Extended NotmuchDataSource Implementation & Data Model Evolution:** In `src/core/notmuch_data_source.py`, ensure the full DataSource interface is not only implemented (`delete_email`, `get_dashboard_aggregates`, `get_category_breakdown`) but also optimized for performance and large datasets. Review and propose necessary schema migrations or adaptations in the underlying data store to accommodate new Notmuch tagging and AI analysis metadata. Ensure `get_dashboard_aggregates` supports complex filtering and time-series aggregation efficiently.\n3.  **Scalable AI Analysis & Categorization Pipeline:** Integrate the AI-powered sentiment analysis and categorization logic as a highly scalable and fault-tolerant background process. This requires implementing a message queue (e.g., Kafka/RabbitMQ) for processing, robust retry mechanisms, and error queues for failed AI jobs. The AI model should support versioning and be configurable for different analysis types (e.g., multilingual). Consider model retraining and deployment strategies.\n4.  **Advanced SmartFilterManager Integration & Rule Engine Extension:** Beyond simple connection, extend `SmartFilterManager` to allow dynamic rule creation and persistence based on AI-derived tags and user-defined criteria. This may require a new domain-specific language (DSL) or configuration interface for defining and applying complex filtering rules that leverage Notmuch tags and AI insights.\n5.  **Hierarchical Tagging & Category Management System:** Implement comprehensive logic for tag-based category mapping, including support for hierarchical tags, tag synonyms, and user-defined categorization rules. This system should provide CRUD operations for tags and categories themselves, allowing for flexible taxonomy management.\n6.  **Distributed Observability & Performance Monitoring:** Integrate comprehensive error reporting, distributed tracing (e.g., OpenTelemetry), and advanced performance monitoring hooks for all new components. Define custom metrics for AI processing latency, accuracy, and background job throughput. Ensure all logs are structured and integrated with a centralized logging solution.\n7.  **End-to-End Security Hardening & Compliance:** Expand security enhancements beyond robust path validation to include input sanitization across all new data entry points, API authentication/authorization for any new internal/external endpoints, data encryption at rest and in transit for sensitive Notmuch data, and adherence to relevant data privacy regulations (e.g., GDPR, CCPA). Conduct a security review of the entire integration.\n8.  **Database Layer Adaptation & Optimization:** Update `src/core/database.py` with any necessary adjustments for compatibility with the enhanced data source, including new data types (e.g., JSONB for flexible metadata, vector embeddings for AI), optimized query patterns for the new aggregation methods, and ensuring transactional integrity for all tagging and AI-related operations. Implement database connection pooling and query caching where beneficial.\n9.  **API Exposure & Documentation:** If new capabilities are exposed via an API, ensure robust, versioned API endpoints are created and fully documented using OpenAPI/Swagger, including security considerations and usage examples.\n10. **Comprehensive Documentation:** Update all relevant design documents, architectural diagrams, and user guides to reflect the new NotmuchDataSource capabilities, AI integration, and tagging system.",
        "testStrategy": "A rigorous and multi-layered testing strategy is required to ensure the stability, correctness, performance, and security of this complex integration:\n1.  **Expanded Regression Test Suite:** Execute a full regression test suite across the entire application to ensure no existing functionality is broken. This must include performance baselining before and after integration to identify any regressions in response times or resource consumption.\n2.  **Detailed Unit & Integration Tests for NotmuchDataSource:** Develop comprehensive unit tests covering all methods of the `NotmuchDataSource`, including edge cases for each (`delete_email` with non-existent IDs, `get_dashboard_aggregates` with various date ranges and filters, `get_category_breakdown` with empty data). Integration tests should thoroughly verify the `NotmuchDataSource`'s interaction with the actual database and `SmartFilterManager`.\n3.  **Advanced AI/Background Process Validation:** Create specific integration tests to verify the end-to-end flow of the background AI analysis and tagging processes. This includes testing message queue interactions, error handling for failed AI jobs (e.g., malformed input, AI model errors), retry mechanisms, and the persistence of AI-derived metadata. Validate AI model accuracy with a diverse test dataset, tracking false positives and negatives.\n4.  **Smart Filtering & Tagging System Validation:** Develop comprehensive tests for the `SmartFilterManager` and the new hierarchical tagging system. This includes validating dynamic rule creation, application, and persistence, as well as complex category mapping scenarios (e.g., overlapping tags, nested categories, tag deprecation).\n5.  **Observability System Verification:** Confirm that new performance metrics, distributed traces, and structured error logs are correctly generated, captured, and accessible through the centralized monitoring system. Validate alert configurations for critical errors and performance thresholds.\n6.  **Comprehensive Security Testing:** Beyond functional security tests, conduct vulnerability scanning, penetration testing simulations (e.g., SQL injection, XSS for new inputs if applicable, broken access control for new endpoints), and data privacy compliance checks. Verify all input sanitization and authorization rules.\n7.  **Performance, Load, and Stress Testing:** Conduct extensive performance testing, including load tests (simulating expected peak usage), stress tests (exceeding peak usage to find breaking points), and soak tests (long-duration tests to detect memory leaks or resource exhaustion). Focus on the `NotmuchDataSource` aggregation methods and AI background processing under high concurrency.\n8.  **Data Migration & Schema Evolution Testing:** Rigorously test any proposed database schema changes or data migrations. This includes testing forward compatibility (new code with old schema) and backward compatibility (old code with new schema, if necessary for rollback plans). Ensure data integrity and consistency throughout the migration process.\n9.  **User Acceptance Testing (UAT):** Plan and execute UAT sessions with key business stakeholders to validate that the new smart tagging, AI analysis results, and filtering capabilities meet business requirements and provide an intuitive user experience.\n10. **Continuous Integration/Continuous Deployment (CI/CD) Integration:** Ensure all newly developed tests, including unit, integration, and security checks, are integrated into the CI/CD pipeline for automated execution on every code change.",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Create Comprehensive Merge Validation Framework",
        "description": "Create a comprehensive validation framework to ensure all architectural updates have been properly implemented before merging scientific branch to main. This framework will leverage research-backed CI/CD practices to validate consistency, functionality, performance, and security across all components, specifically tailored for our Python/FastAPI application. This task is directly linked to the backlog item: `backlog/tasks/alignment/create-merge-validation-framework.md`.",
        "status": "pending",
        "dependencies": [],
        "priority": "high",
        "details": "This framework will integrate into the GitHub Actions CI/CD pipeline, triggered on pull requests to the `main` branch from `scientific`. It will encompass several layers of automated checks, including:\n1.  **Architectural Enforcement**: Static analysis to ensure `src/backend` adheres to defined module boundaries and import rules.\n2.  **Functional Correctness**: Execution of full unit/integration test suites for `src/backend` and end-to-end smoke tests against a deployed instance of the FastAPI application.\n3.  **Performance Benchmarking**: Automated checks for performance regressions on critical FastAPI endpoints.\n4.  **Security Validation**: Dependency vulnerability scanning and Static Application Security Testing (SAST) for the Python/FastAPI codebase.\nThe ultimate goal is to automatically block merges if any of these validation layers fail, ensuring a robust and secure `main` branch. The framework will be configured to analyze the `src/backend` directory primarily.",
        "testStrategy": "The overall test strategy involves validating each component of the framework individually, then ensuring their integrated operation correctly blocks or permits merges based on the validation outcomes. This will include creating test PRs with deliberate failures (architectural, functional, performance, security) and successes to verify the framework's decision-making.",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Validation Scope and Acceptance Criteria",
            "description": "Document the specific architectural rules, functional requirements, performance benchmarks, and security requirements that will be validated by the framework before any code is written.",
            "dependencies": [],
            "details": "Create a markdown document (e.g., `docs/ci-cd/VALIDATION_CRITERIA.md`) in the repository. It must list: 1) Architectural rules like module boundaries and import restrictions for the `src/backend` structure. 2) Key functional user flows for smoke testing of the FastAPI application. 3) Performance baseline metrics (e.g., API response times, memory usage) for critical FastAPI endpoints. 4) Security requirements and vulnerability thresholds (e.g., OWASP Top 10, dependency vulnerability scanning thresholds). This document will serve as the single source of truth for the validation framework's goals.",
            "status": "pending",
            "testStrategy": "Review the generated document with the lead architect and senior developers to ensure consensus, completeness, and feasibility of the defined criteria."
          },
          {
            "id": 2,
            "title": "Configure CI Pipeline Trigger for 'scientific' Branch Pull Requests",
            "description": "Set up a dedicated CI/CD workflow that triggers automatically when a pull request is opened from the 'scientific' branch to 'main'.",
            "dependencies": [
              1
            ],
            "details": "Create a new GitHub Actions workflow file (`.github/workflows/merge_validation.yml`). Configure it to trigger on pull requests targeting the 'main' branch. This initial version will only define the trigger and placeholder jobs for subsequent validation steps, ensuring it correctly checks out the PR code from the `src/backend` context.",
            "status": "pending",
            "testStrategy": "Create a test pull request from a temporary branch to 'main' and verify that the new CI pipeline is triggered automatically and completes its initial placeholder steps successfully."
          },
          {
            "id": 3,
            "title": "Implement Architectural Consistency Checks",
            "description": "Integrate static analysis tools into the CI pipeline to automatically enforce the architectural rules defined in the scope for the Python/FastAPI application.",
            "dependencies": [
              2
            ],
            "details": "Utilize a tool like `Pylint` (for module import rules), `Adept` (for dependency graph analysis), or a custom Python script leveraging `ast` module parsing to enforce architectural rules defined in `docs/ci-cd/VALIDATION_CRITERIA.md`. This will check module boundaries and import restrictions specific to the `src/backend` structure. Add a new step in the `.github/workflows/merge_validation.yml` CI workflow that runs this analysis. The step must fail the build if any architectural violations are detected, such as a feature module importing from another feature module within `src/backend`.",
            "status": "pending",
            "testStrategy": "Create a test branch with a deliberate architectural violation (e.g., an illegal import statement within `src/backend`). Open a PR and verify that the CI pipeline fails at the static analysis step with a clear, actionable error message highlighting the Python module violation."
          },
          {
            "id": 4,
            "title": "Integrate Full Regression Test Suite Execution",
            "description": "Add a job to the validation pipeline that executes the complete backend test suite (unit and integration tests) to ensure no existing functionality is broken in the FastAPI application.",
            "dependencies": [
              2
            ],
            "details": "Add a new job to the `.github/workflows/merge_validation.yml` file. This job will install all project dependencies (e.g., from `requirements.txt` in the root or `src/backend/requirements.txt`) and then execute the full test suite using `pytest` from the `src/backend` directory. The job must be configured to fail the entire pipeline run if any single test fails. Ensure the test environment is correctly configured with all necessary services (e.g., database, cache) required for the FastAPI application.",
            "status": "pending",
            "testStrategy": "Manually introduce a failing test in a new PR within `src/backend` to ensure the pipeline correctly identifies the failure, reports it, and blocks the merge. Verify that the logs show the complete test suite was executed."
          },
          {
            "id": 5,
            "title": "Develop and Integrate E2E Smoke Tests",
            "description": "Create and run a suite of automated end-to-end (E2E) smoke tests against a live instance of the FastAPI application to verify critical user flows.",
            "dependencies": [
              4
            ],
            "details": "Using `pytest` with `httpx` (or `requests`), write tests that simulate core FastAPI application workflows (e.g., user authentication, data submission, primary resource retrieval) against the `src/backend` service. The CI pipeline will need a step to build a Docker container for the PR's code (e.g., from `src/backend/Dockerfile`), run it, expose the FastAPI application, and then execute these smoke tests against the running container's API.",
            "status": "pending",
            "testStrategy": "Run the smoke tests locally against a developer environment to validate the test logic. Then, trigger the CI pipeline and confirm it correctly builds the container, runs the application, and executes the smoke tests, failing the build if a test fails."
          },
          {
            "id": 6,
            "title": "Implement Automated Performance Benchmark Testing",
            "description": "Create and integrate performance tests for critical FastAPI API endpoints to automatically detect and flag performance regressions.",
            "dependencies": [
              5
            ],
            "details": "Use a tool like `locust` or `pytest-benchmark` within `pytest` to measure key performance indicators (KPIs) like p95 response time for 5-10 critical FastAPI endpoints from `src/backend`. Establish a baseline by running these tests against the 'main' branch. The CI script will compare the PR's performance against this baseline and fail if it exceeds a defined threshold (e.g., 15% degradation). The performance test environment should closely mimic production conditions for the FastAPI service.",
            "status": "pending",
            "testStrategy": "Establish the performance baseline. Then, create a PR with an intentionally inefficient code change (e.g., adding a `time.sleep()` in a hot path within `src/backend`) and verify that the performance test detects the regression, reports the deviation, and fails the pipeline."
          },
          {
            "id": 7,
            "title": "Implement Automated Security Vulnerability Scanning",
            "description": "Integrate automated security scanning tools into the CI pipeline to identify known vulnerabilities in dependencies and potential security weaknesses in the Python/FastAPI application code.",
            "dependencies": [
              2
            ],
            "details": "Add a new job to the `.github/workflows/merge_validation.yml` file. This job will perform two types of scans: 1) Dependency vulnerability scanning using tools like `safety` or `pip-audit` against `requirements.txt` (or similar dependency files in `src/backend`). 2) Static Application Security Testing (SAST) using tools like `Bandit` or `Pylint` with security checks configured, targeting the Python code in `src/backend`. Configure the job to fail the pipeline if critical or high-severity vulnerabilities are found, or if SAST rules are violated.",
            "status": "pending",
            "testStrategy": "Introduce a known vulnerable dependency (e.g., an old version of a common library) or a simple security flaw (e.g., hardcoded credentials) into a test branch in `src/backend`. Verify the CI pipeline correctly identifies and flags these issues, failing the build as appropriate and providing clear output."
          },
          {
            "id": 8,
            "title": "Generate and Publish a Unified Validation Report",
            "description": "Configure the CI pipeline to aggregate results from all validation steps into a single report and publish it as a comment on the pull request.",
            "dependencies": [
              3,
              4,
              6
            ],
            "details": "Use a GitHub Action (like 'actions/github-script') in a final pipeline job to generate a markdown summary of the results. The report should include the status of architectural checks, test suite results (e.g., '1573/1573 passed'), performance benchmark deltas, and security scan findings. This job will post the markdown summary as a comment on the associated PR.",
            "status": "pending",
            "testStrategy": "Trigger the pipeline on a test PR and check that a comment is successfully posted. Verify the comment's content accurately reflects the success or failure of the preceding steps. Check both a fully successful run and a run with a failure."
          },
          {
            "id": 9,
            "title": "Enforce Merge Blocking via Branch Protection Rules",
            "description": "Configure repository branch protection rules to make the merge validation pipeline a required check, preventing merges to 'main' if any validation fails.",
            "dependencies": [
              7
            ],
            "details": "In the GitHub repository settings, navigate to 'Branches' and edit the protection rule for the 'main' branch. Under 'Require status checks to pass before merging', add the merge validation CI job. This will physically disable the merge button on pull requests until the check passes.",
            "status": "pending",
            "testStrategy": "Open a new PR from 'scientific' to 'main' with a change that causes the validation pipeline to fail. Verify that the GitHub UI blocks the merge. Then, push a fix, wait for the pipeline to pass, and confirm the merge button becomes active again."
          }
        ]
      },
      {
        "id": 8,
        "title": "Update Setup Subtree Integration in Scientific Branch",
        "description": "Update the scientific branch to use the new setup subtree methodology that has been implemented in the main branch. This will align the architecture for easier merging and future maintenance, as detailed in the original backlog task: backlog/tasks/alignment/update-setup-subtree-integration.md.",
        "status": "pending",
        "dependencies": [],
        "priority": "high",
        "details": "",
        "testStrategy": "",
        "subtasks": [
          {
            "id": 1,
            "title": "Analyze 'main' branch for setup subtree methodology",
            "description": "Investigate the 'main' branch's Git history and current filesystem to understand the precise implementation details of the 'new setup subtree methodology'. This includes identifying the subtree's remote URL, its local path within the 'main' branch, and the specific `git subtree` commands used for its integration and updates. Pay close attention to any associated scripts or configuration files.",
            "dependencies": [],
            "details": "Use `git log --grep='git subtree'` on the 'main' branch to find relevant commit messages. Examine the `.git/config` file in 'main' for subtree-related entries. Identify the exact path where the subtree is mounted (e.g., 'src/setup' or 'shared/config') and the remote repository it points to. Check for any automation scripts in `scripts/` or `tools/` that manage the subtree.",
            "status": "pending",
            "testStrategy": null
          },
          {
            "id": 2,
            "title": "Identify and isolate target directory in 'scientific' branch",
            "description": "Pinpoint the specific directory or set of files within the 'scientific' branch that corresponds to the 'setup' functionality now managed by the new subtree methodology in 'main'. This content will be replaced or integrated with the subtree.",
            "dependencies": [
              1
            ],
            "details": "Based on the findings from subtask 1 (e.g., if the main branch uses 'src/setup' for the subtree), identify the equivalent directory in the 'scientific' branch. Verify its content aligns with what is expected from the 'setup' component. Create a temporary `temp_backup_scientific_setup` directory.",
            "status": "pending",
            "testStrategy": "Verify the identified directory path and its contents against the expected setup component. Confirm this is the correct target for subtree replacement."
          },
          {
            "id": 3,
            "title": "Backup and remove existing setup code in 'scientific' branch",
            "description": "Before integrating the new setup subtree, create a complete backup of the existing 'setup' related code found in the 'scientific' branch. After backup, safely remove this existing code to ensure a clean slate for the subtree integration and prevent potential conflicts.",
            "dependencies": [
              2
            ],
            "details": "Copy the identified 'setup' directory (e.g., 'src/setup') from the 'scientific' branch to a temporary, version-controlled backup location (e.g., a new branch or a dedicated commit). Then, use `git rm -r <path_to_setup_directory>` to remove the existing directory from the 'scientific' branch's working tree and stage the deletion. Commit these changes.",
            "status": "pending",
            "testStrategy": "After removal, run `git status` to confirm the directory is gone. Attempt to build the project (if applicable) to ensure no immediate, critical build failures due to missing files (expect failures, but ensure it's clean)."
          },
          {
            "id": 4,
            "title": "Integrate the new setup subtree into 'scientific' branch",
            "description": "Add the 'setup' component from its designated remote repository as a `git subtree` into the 'scientific' branch, following the methodology identified in the 'main' branch. This step establishes the official link and pulls in the latest 'setup' code.",
            "dependencies": [
              3
            ],
            "details": "Using the remote URL and path identified in subtask 1, execute the `git subtree add --prefix=<path_in_scientific> <remote_url> <branch_name> --squash` command. For example, `git subtree add --prefix=src/setup https://github.com/org/setup-repo.git main --squash`. Commit the changes after successful addition. If the 'main' branch uses `git subtree pull` from an existing remote, ensure that remote is added first.",
            "status": "pending",
            "testStrategy": "Verify the new directory structure for the subtree appears at the correct path. Check `git log` to confirm the subtree addition commit. Attempt a basic project build to ensure the newly added files are recognized."
          },
          {
            "id": 5,
            "title": "Reconcile 'scientific' branch-specific modifications",
            "description": "Carefully identify and re-apply any unique modifications, configurations, or extensions that were present in the 'scientific' branch's original 'setup' code (backed up in subtask 3) but are not part of the newly integrated subtree. This ensures feature parity for the 'scientific' branch.",
            "dependencies": [
              4
            ],
            "details": "Using the backup created in subtask 3, perform a diff between the backup and the newly integrated subtree content. Manually merge or re-apply any custom logic, configuration changes, or additional files that are specific to the 'scientific' branch's requirements. Resolve any merge conflicts that arise during this process. Commit these reconciliation changes.",
            "status": "pending",
            "testStrategy": "Perform detailed code review of re-applied changes. Run unit tests specific to the 'setup' component, if available, to ensure custom logic behaves as expected. Manually verify configurations are correct."
          },
          {
            "id": 6,
            "title": "Verify and test setup subtree functionality",
            "description": "Thoroughly test the newly integrated setup subtree to ensure all functionalities related to the 'setup' component work correctly within the 'scientific' branch. This includes validating configurations, dependencies, and any interactions with other parts of the system.",
            "dependencies": [
              5
            ],
            "details": "Execute the full suite of unit, integration, and end-to-end tests related to the 'setup' component. If the 'setup' component is responsible for environment configuration or build processes, run full build processes and test environment startup. Pay special attention to areas where 'scientific' branch had specific modifications. Ensure proper loading of configurations and dependencies.",
            "status": "pending",
            "testStrategy": "Run all existing test suites. Develop new integration tests for critical 'setup' functionalities if existing coverage is insufficient. Deploy to a staging environment for full system integration testing to ensure no regressions."
          }
        ]
      },
      {
        "id": 9,
        "title": "Align import-error-corrections Branch with Main Branch",
        "description": "Systematically align feature branch `fix/import-error-corrections` with the main branch. This alignment will carefully preserve the key business logic and unique features of the `fix/import-error-corrections` branch, focusing updates primarily on architectural and common files from the main branch to minimize unnecessary conflicts, while ensuring feature-specific work is maintained. This task is linked to the original backlog item: `backlog/tasks/alignment/task-feature-branch-alignment-import-error-corrections-main.md`.",
        "status": "pending",
        "dependencies": [],
        "priority": "low",
        "details": "",
        "testStrategy": "",
        "subtasks": [
          {
            "id": 1,
            "title": "Ensure clean working directory and checkout feature branch",
            "description": "Before starting the alignment process, ensure there are no uncommitted changes in the local repository and checkout the target feature branch `fix/import-error-corrections`.",
            "dependencies": [],
            "details": "Use `git status` to confirm a clean working directory. If necessary, stash or commit any local changes. Then, execute `git checkout fix/import-error-corrections`.",
            "status": "pending",
            "testStrategy": null
          },
          {
            "id": 2,
            "title": "Update local 'main' branch to latest remote",
            "description": "Synchronize the local 'main' branch with the upstream 'main' branch to ensure the feature branch will be rebased against the most recent changes.",
            "dependencies": [
              1
            ],
            "details": "First, switch to the main branch (`git checkout main`), then fetch and pull the latest changes from the remote (`git pull origin main`).",
            "status": "pending",
            "testStrategy": null
          },
          {
            "id": 3,
            "title": "Run baseline tests on 'fix/import-error-corrections'",
            "description": "Execute the existing test suite on the `fix/import-error-corrections` branch to establish a functional baseline before applying changes from 'main'.",
            "dependencies": [
              2
            ],
            "details": "Switch back to the feature branch (`git checkout fix/import-error-corrections`). Run all relevant unit, integration, and end-to-end tests for the project. Document any existing failures or unexpected behaviors.",
            "status": "pending",
            "testStrategy": "Capture test results (e.g., screenshots of test runner output, log files) to compare against post-rebase results."
          },
          {
            "id": 4,
            "title": "Rebase 'fix/import-error-corrections' onto 'main'",
            "description": "Perform the Git rebase operation to integrate the `main` branch's history into `fix/import-error-corrections`, ensuring a linear commit history.",
            "dependencies": [
              3
            ],
            "details": "While on the `fix/import-error-corrections` branch, execute `git rebase main`. This will apply the commits from the feature branch on top of the latest 'main' commit.",
            "status": "pending",
            "testStrategy": null
          },
          {
            "id": 5,
            "title": "Resolve rebase conflicts",
            "description": "Address and resolve any merge conflicts that arise during the rebase process to ensure code integrity and functionality.",
            "dependencies": [
              4
            ],
            "details": "Upon encountering conflicts, use `git status` to identify conflicting files. Edit these files to resolve conflicts, then stage them (`git add <file>`) and continue the rebase (`git rebase --continue`). Repeat until the rebase is complete.",
            "status": "pending",
            "testStrategy": "Thoroughly review each conflict resolution to ensure correct code merging and no introduction of new bugs."
          },
          {
            "id": 6,
            "title": "Run full test suite post-rebase",
            "description": "After successfully rebasing and resolving conflicts, run the entire project's test suite to verify that no regressions or new issues were introduced.",
            "dependencies": [
              5
            ],
            "details": "Execute all unit, integration, and end-to-end tests on the rebased `fix/import-error-corrections` branch. Compare results with the baseline tests from subtask 3.",
            "status": "pending",
            "testStrategy": "All tests must pass. If any tests fail, debug and fix the issues introduced by the rebase, then re-run tests. Document any new issues."
          },
          {
            "id": 7,
            "title": "Perform local functional validation and code review",
            "description": "Conduct a manual review of the aligned code and perform functional tests specific to the `import-error-corrections` feature to ensure it still works as expected.",
            "dependencies": [
              6
            ],
            "details": "Manually test the `import-error-corrections` functionality. Review the changes introduced from 'main' to ensure they integrate logically with the feature branch's code. Pay attention to any areas that had conflicts.",
            "status": "pending",
            "testStrategy": "Verify the core functionality addressed by `fix/import-error-corrections` still works correctly. Check for unexpected side effects from the `main` branch's changes."
          },
          {
            "id": 8,
            "title": "Force push rebased branch and notify team",
            "description": "Once validation is complete, force push the rebased `fix/import-error-corrections` branch to the remote repository and inform relevant team members.",
            "dependencies": [
              7
            ],
            "details": "Execute `git push --force-with-lease origin fix/import-error-corrections`. Notify the development team, especially those who might be working on or depending on this branch, about the successful rebase and updated remote branch.",
            "status": "pending",
            "testStrategy": null
          }
        ]
      },
      {
        "id": 10,
        "title": "Improve Task Management with Advanced Testing Integration",
        "description": "Enhance Task Master AI with automated testing validation, branch-specific task tracking, and integration with scientific branch's advanced testing frameworks. This will ensure tasks include proper testing requirements and validation before completion.",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "details": "This task focuses on integrating robust testing validation and tracking into the Task Master AI system. The implementation will leverage the existing CI/CD infrastructure (`.github/workflows/main.yml`) which already uses `pytest` for testing and Codecov for coverage reporting across `src/backend/tests` and `src/data_platform/tests`. Specific attention will be given to the unique testing requirements of the `scientific` branch, as indicated by the `scientific_branch_specific_checks` job in the workflow. The goal is to enforce testing requirements at task creation and automate validation checks during the task completion workflow, ensuring high code quality and reliability.",
        "testStrategy": "Testing will involve a multi-faceted approach. Modifications to the CI/CD workflow (`.github/workflows/main.yml`) will be validated through creation of draft pull requests and observation of workflow runs for various branch types (e.g., `main`, `scientific`, `feature/`, `feature/scientific-`). Unit tests will be developed for any new backend services or logic interacting with the task management system, located within `src/backend/tests`. Integration tests will ensure seamless communication between the CI/CD pipeline and the Task Master system, verifying correct status updates and enforcement of validation rules. Specific test cases will target the unique validation needs of the `scientific` branch.",
        "subtasks": [
          {
            "id": 1,
            "title": "Integrate automated testing validation into task completion workflow",
            "description": "Implement a mechanism within the CI/CD pipeline (`.github/workflows/main.yml`) to automatically validate test results (e.g., `pytest` pass/fail, coverage thresholds via Codecov) before allowing a task to be marked as complete in the Task Master system. This implies Task Master will need to consume CI/CD status.",
            "dependencies": [],
            "details": "Modify the `.github/workflows/main.yml` to enhance the reporting of `pytest` test results and Codecov coverage. Ensure that the CI run for a branch or pull request can publish a consolidated status (pass/fail, coverage metrics) that can be consumed by the Task Master system. Develop or identify an existing API endpoint within `src/backend/api` or a new service in `src/backend/services` that can receive and process these CI/CD status updates. Implement logic to verify that all `pytest` tests passed and that code coverage, as reported by Codecov, meets predefined thresholds for the associated code changes.",
            "status": "done",
            "testStrategy": "Create a dummy pull request with passing tests and sufficient coverage to verify the CI reports success to Task Master. Create another dummy pull request with failing tests or insufficient coverage to confirm Task Master correctly flags the task. Unit tests will be written for the new validation logic in `src/backend/tests`."
          },
          {
            "id": 2,
            "title": "Add branch-specific task tracking and validation",
            "description": "Extend the task management system to associate tasks with specific Git branches (e.g., `feature/task-10-validation`) and enforce validation rules based on the branch type. This will leverage the existing branch-aware logic in `.github/workflows/main.yml`.",
            "dependencies": [
              1
            ],
            "details": "Update the Task Master system to store and display the associated Git branch or pull request for each task. Enhance the `.github/workflows/main.yml` to utilize `github.head_ref` or `github.ref_name` to identify the current branch. Implement conditional steps within the CI/CD (similar to the `scientific_branch_specific_checks` job) to apply different validation criteria or invoke specialized tests based on branch naming conventions (e.g., `feature/scientific-*` branches may trigger additional checks). Ensure Task Master correctly interprets and reacts to these branch-specific validation outcomes received from the CI/CD.",
            "status": "pending",
            "testStrategy": "Create multiple test branches with different naming conventions (e.g., `feature/standard-task-A`, `feature/scientific-task-B`). Create pull requests for these branches and verify that the CI/CD pipeline applies the correct branch-specific validation rules. Confirm Task Master accurately reflects the validation status for each task based on its associated branch type."
          },
          {
            "id": 3,
            "title": "Incorporate scientific branch testing frameworks into Task Master",
            "description": "Integrate the advanced testing frameworks and specific test suites used in the `scientific` branch into Task Master's validation process. This directly builds upon the `scientific_branch_specific_checks` job in `.github/workflows/main.yml`.",
            "dependencies": [
              1,
              2
            ],
            "details": "Enhance the `scientific_branch_specific_checks` job in `.github/workflows/main.yml`. Currently, this job explicitly runs `pytest tests/data_sources/test_notmuch_data_source.py` within `scientific_branch/src/data_platform`. Expand this job to include any other 'additional scientific-specific testing frameworks' or more comprehensive `pytest` suites located in `src/data_platform/tests` that are critical for `scientific` branch validation. Ensure that the results of these specialized scientific tests are captured and reported back to Task Master, potentially using the same mechanism developed for general automated testing validation. Configure Task Master to distinctly recognize and display these 'scientific branch' test outcomes as a required validation stage for relevant tasks.",
            "status": "pending",
            "testStrategy": "Develop a feature branch with a `feature/scientific-` prefix. Introduce a small, new scientific-specific test file in `src/data_platform/tests` or modify an existing `scientific` test. Create a pull request and verify that the `scientific_branch_specific_checks` job executes the scientific tests, and their results are accurately reported back to Task Master."
          },
          {
            "id": 4,
            "title": "Implement testing requirement enforcement in task creation",
            "description": "Modify the task creation process within Task Master to enforce the definition of testing requirements (e.g., type of tests, coverage goals) from the outset.",
            "dependencies": [],
            "details": "Update the data model or schema for tasks within the Task Master system to include mandatory fields such as `required_test_types` (e.g., 'unit', 'integration', 'scientific-specific') and `minimum_coverage_percentage`. If Task Master has a user interface or API for creating tasks, modify these interfaces to enforce the input of these testing requirements. Provide updated documentation for developers on how to specify these requirements when creating new tasks. Consider optional integration of pre-commit hooks or static analysis tools to encourage adherence to these testing requirements during code development, possibly referencing existing test directories like `src/backend/tests` and `src/data_platform/tests`.",
            "status": "pending",
            "testStrategy": "Attempt to create tasks through the Task Master API/UI without specifying the new mandatory testing requirement fields, and verify that the creation fails with an appropriate error. Successfully create tasks with valid testing requirements specified, and confirm these requirements are correctly stored and displayed. Develop and run unit tests for the task creation logic."
          }
        ]
      }
      ,
       {
         "id": 9,
         "title": "Complete Email Intelligence Core Development",
         "description": "Execute comprehensive core development plan focusing on architectural improvements, security, testing, and performance optimization using scientific branch as foundation",
         "status": "pending",
         "dependencies": [1, 2],
         "priority": "high",
         "details": "Phase 1: Foundation Consolidation - Refactor AI modules from scientific branch and integrate backend migration\nPhase 2: Security Implementation - Leverage scientific's security enhancements (RBAC, MFA, auditing)\nPhase 3: Quality Assurance - Utilize scientific's comprehensive testing (90+ test files)\nPhase 4: Performance Optimization - Build on scientific's monitoring and AI engine optimizations",
         "testStrategy": "Each phase validated through automated testing, code reviews, and performance benchmarks using scientific branch's advanced infrastructure",
         "subtasks": [
           {
             "id": 1,
             "title": "Refactor High-Complexity AI Modules",
             "description": "Break down monolithic smart_filters.py (1598 lines) and smart_retrieval.py (1198 lines) from scientific branch into modular packages",
              "status": "pending",
             "dependencies": [2],
             "details": "Extract rule_parsers.py, filter_evaluators.py, data_transformers.py from smart_filters.py\nExtract query_builders.py, ranking_algorithms.py, source_integrations.py from smart_retrieval.py\nImplement dependency injection and maintain 100% test coverage using scientific's testing framework",
             "testStrategy": "Unit tests for each new module, integration tests for refactored functionality, leverage scientific's 90+ test files"
           },
            {
              "id": 2,
              "title": "Integrate Backend Migration",
              "description": "Merge feature/backend-to-src-migration from scientific branch and update all imports",
              "status": "pending",
              "dependencies": [],
              "details": "Validate migration completeness using scientific's advanced backend (20+ modules), update import references, merge to scientific, run full test suite",
              "testStrategy": "Import validation, regression testing, functionality verification using scientific's comprehensive testing"
            },
           {
             "id": 3,
             "title": "Leverage Scientific Security Framework",
             "description": "Integrate and enhance scientific branch's security features (RBAC, MFA, auditing, node engine security)",
             "status": "pending",
             "dependencies": [2],
             "details": "Review and integrate scientific's security_manager.py, authentication enhancements, and audit logging. Add any missing security features from main branch.",
             "testStrategy": "Security unit tests, integration tests using scientific's security test suite"
           },
           {
             "id": 4,
             "title": "Security Testing & Validation",
             "description": "Implement comprehensive security testing using scientific's advanced testing infrastructure",
             "status": "pending",
             "dependencies": [3],
             "details": "Leverage scientific's security test suite, vulnerability scanning, compliance validation, audit verification",
             "testStrategy": "Automated security scans, manual testing, compliance audits using scientific's testing framework"
           },
           {
             "id": 5,
             "title": "Comprehensive Testing Integration",
             "description": "Utilize and enhance scientific's extensive testing infrastructure (90+ test files, comprehensive coverage)",
             "status": "pending",
             "dependencies": [2],
             "details": "Review scientific's testing framework, ensure 90%+ coverage maintained, add missing tests, integrate API and performance testing",
             "testStrategy": "Coverage reports, automated test execution, regression prevention using scientific's advanced testing"
           },
           {
             "id": 6,
             "title": "CI/CD Pipeline Enhancement",
             "description": "Enhance CI/CD pipeline using scientific's workflow orchestration and monitoring",
             "status": "pending",
             "dependencies": [5],
             "details": "Leverage scientific's orchestration tools, enhance GitHub Actions, integrate scientific's monitoring dashboard",
             "testStrategy": "Pipeline validation, deployment testing, rollback verification using scientific's monitoring"
           },
           {
             "id": 7,
             "title": "Database Performance Optimization",
             "description": "Optimize database using scientific's performance monitoring and optimization features",
             "status": "pending",
             "dependencies": [2],
             "details": "Leverage scientific's performance_monitor.py, optimize queries, implement connection pooling, enhance caching",
             "testStrategy": "Performance benchmarks, query analysis, load testing using scientific's monitoring tools"
           },
           {
             "id": 8,
             "title": "AI Engine Performance Optimization",
             "description": "Enhance AI engine using scientific's advanced AI infrastructure and monitoring",
             "status": "pending",
             "dependencies": [1],
             "details": "Leverage scientific's AI training routes, model management, batch processing, and performance monitoring",
             "testStrategy": "Inference benchmarks, memory profiling, concurrent load testing using scientific's AI monitoring"
           },
           {
             "id": 9,
             "title": "System Monitoring & Alerting",
             "description": "Integrate scientific's comprehensive monitoring and orchestration system",
             "status": "pending",
             "dependencies": [2],
             "details": "Utilize scientific's orchestration status monitoring, performance monitoring dashboard, and alerting system",
             "testStrategy": "Monitoring validation, alert testing, incident simulation using scientific's monitoring infrastructure"
           }
         ]
       }
    ],
    "metadata": {
      "created": "2025-11-06T04:11:47.735Z",
      "updated": "2025-11-06T06:25:04.818Z",
      "description": "Tasks for master context"
    }
  }
}
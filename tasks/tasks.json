{
  "master": {
    "tasks": [
      {
        "id": 4,
        "title": "Backend Migration from 'backend' to 'src/backend'",
        "description": "Execute the complete structural migration of the legacy 'backend' package to the new modular architecture under 'src/backend'. This is a critical architectural improvement to modernize the codebase and enable further development.",
        "details": "1. Create a new branch from the main development branch after the code recovery (Task 1) is merged. 2. Physically move the entire `backend` directory into `src/` and rename it to `src/backend`. 3. Perform a project-wide find-and-replace to update all Python import statements from `from backend...` to `from src.backend...`. Use a tool like `sed`, `grep`, or an and an IDE's refactoring capabilities. 4. Update any configuration files that reference the old path. This includes `PYTHONPATH` definitions in Dockerfiles (`ENV PYTHONPATH=\"/app/src:$PYTHONPATH\"`), `docker-compose.yml`, CI/CD pipeline scripts (e.g., `.github/workflows/ci.yml`), and potentially `pyproject.toml` if using editable installs. 5. After all tests pass, delete the original top-level `backend` directory. 6. Ensure `src/__init__.py` and `src/backend/__init__.py` exist to make them valid packages.\n\n### Tags:\n- `work_type:refactoring`\n- `component:backend-core`\n- `scope:architectural`\n- `purpose:modernization`, `maintainability`",
        "testStrategy": "The primary validation method is comprehensive regression testing. Run the full existing test suite and ensure 100% of tests pass. Perform a manual smoke test of the application by starting it and hitting key API endpoints using Postman or cURL to confirm it is fully functional. The application's behavior must be identical to the pre-migration state. No new feature tests are required for this task.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Move Backend Files to src/",
            "description": "Move all source code from the 'backend' directory to the new 'src/backend' directory. This is the first step in the migration process.",
            "dependencies": [],
            "details": "Physically move the entire `backend` directory from the project root into `src/` and rename it to `src/backend`. This foundational step establishes the new modular architecture.",
            "status": "pending",
            "testStrategy": null
          },
          {
            "id": 2,
            "title": "Update Imports and References",
            "description": "Update all internal imports and external references throughout the codebase to reflect the new 'src/backend' path. This includes imports in both backend and frontend code.",
            "dependencies": [],
            "details": "Perform a project-wide find-and-replace to update all Python import statements from `from backend...` to `from src.backend...`. Utilize an IDE's refactoring capabilities or a tool like `sed` for this crucial update.",
            "status": "pending",
            "testStrategy": null
          },
          {
            "id": 3,
            "title": "Update Configuration Files",
            "description": "Update any configuration files that reference the old path. This includes `PYTHONPATH` definitions in `Dockerfile`s (e.g., `ENV PYTHONPATH=\"/app/src:$PYTHONPATH\"`), `docker-compose.yml`, CI/CD pipeline scripts (e.g., `.github/workflows/ci.yml`), and potentially `pyproject.toml` if using editable installs. Also, ensure `src/__init__.py` and `src/backend/__init__.py` exist to make them valid Python packages.",
            "dependencies": [],
            "details": "Update any configuration files that reference the old path. This includes `PYTHONPATH` definitions in `Dockerfile`s (e.g., `ENV PYTHONPATH=\"/app/src:$PYTHONPATH\"`), `docker-compose.yml`, CI/CD pipeline scripts (e.g., `.github/workflows/ci.yml`), and potentially `pyproject.toml` if using editable installs. Also, ensure `src/__init__.py` and `src/backend/__init__.py` exist to make them valid Python packages.",
            "status": "pending",
            "testStrategy": null
          },
          {
            "id": 4,
            "title": "Run and Fix Tests",
            "description": "Run the full test suite to ensure that the migration has not introduced any regressions. Fix any failing tests.",
            "dependencies": [],
            "details": "Execute the full existing test suite across the migrated codebase and ensure 100% of tests pass. Address any failures by debugging and correcting import paths, logic, or configuration mismatches introduced by the move. Perform a manual smoke test of the application by starting it and hitting key API endpoints using Postman or cURL to confirm it is fully functional.",
            "status": "pending",
            "testStrategy": null
          },
          {
            "id": 5,
            "title": "Final Cleanup",
            "description": "Remove the original 'backend' directory from the project. This is the final step in the migration process.",
            "dependencies": [],
            "details": "After all tests pass and functional verification is complete, safely delete the original top-level `backend` directory. Ensure no lingering files or references remain that could cause confusion or issues.",
            "status": "pending",
            "testStrategy": null
          }
        ]
      },
      {
        "id": 6,
        "title": "Refactor High-Complexity Modules and Duplicated Code",
        "description": "Improve code quality by refactoring large modules (`smart_filters.py`, `smart_retrieval.py`), reducing code duplication in AI engine modules, and simplifying high-complexity functions as identified in the PRD, applying research-backed refactoring best practices. This task is linked to the backlog item: `backlog/tasks/ai-nlp/task-10 - Code-Quality-Refactoring-Split-large-NLP-modules,-reduce-code-duplication,-and-break-down-high-complexity-functions.md`.",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "details": "This refactoring will be performed on the new `src/backend` structure, incorporating modern refactoring best practices and an incremental, test-driven approach.\n\n1.  **Module Splitting & Incremental Refactoring for `smart",
        "testStrategy": "This is a pure refactoring task; no new functionality should be introduced, and the external behavior of the system must remain unchanged. A robust test-driven refactoring strategy will be employed:\n1.  **Pre-refactoring Characterization Tests (Golden Master)**: Before initiating any changes, ensure all target modules (`src/backend/smart_filters.py`, `src/backend/smart_retrieval.py`, `src/backend/ai/email_filter_node.py`, `src/backend/dependencies.py`, `src/backend/utils/database.py`, and any relevant AI engine modules) have comprehensive test coverage. If coverage is lacking, write 'characterization tests' (also known as 'golden master tests') to rigorously capture and lock in the current observable behavior, even if it's imperfect. These tests are critical to ensure functional equivalence post-refactoring.\n2.  **Incremental Testing and Verification**: After *each small, atomic refactoring step* (e.g., extracting a single method, moving a set of functions to a new module, changing an import), immediately run the relevant test suite (including characterization tests) to catch regressions early. This iterative testing approach is fundamental to safe and effective refactoring. The goal is to always have a green test suite.\n3.  **Behavioral Preservation**: All existing tests for the modified code must pass without any alterations to the tests themselves. The external behavior of the system should remain unchanged. New tests should only be added to cover newly extracted units or to improve coverage where it was initially insufficient for safe refactoring.\n4.  **Static Analysis Integration and Monitoring**: \n    *   **Baseline**: Run a static analysis tool like `radon` (`radon cc -a .` for cyclomatic complexity and `radon mi -a .` for maintainability index) across the codebase (or targeted modules) *before* starting the refactoring to establish a quantitative baseline for complexity and maintainability.\n    *   **Continuous Monitoring**: Integrate these checks into a pre-commit hook or CI/CD pipeline if possible. Alternatively, run them regularly during the refactoring process to monitor progress, ensuring complexity metrics decrease and maintainability indices improve. Tools like `pylint` and `flake8` should also be run to enforce coding standards and identify potential issues.\n    *   **Post-refactoring Verification**: Re-run `radon`, `pylint`, and `flake8` after the refactoring is complete to quantify the reduction in cyclomatic complexity, confirm improved maintainability, and verify adherence to coding standards, thereby proving the task's success.\n5.  **Performance Check**: Conduct basic performance smoke tests or run existing benchmarks to ensure that the refactoring has not introduced any significant performance degradations, especially in critical paths involving the AI engine or data processing. Tools like `cProfile` can be used for targeted analysis if needed.",
        "subtasks": [
          {
            "id": 1,
            "title": "Split 'smart_filters.py' into cohesive modules",
            "description": "Decompose the large 'smart_filters.py' module into smaller, single-responsibility modules, each handling a specific filtering concern to improve modularity and maintainability.",
            "dependencies": [],
            "details": "Identify distinct logical blocks within 'smart_filters.py' related to different filtering mechanisms or data types (e.g., query filtering, results filtering by relevance). Create new Python files (e.g., 'query_filters.py', 'result_filters.py') and move relevant functions and classes into them. Ensure proper import updates across the codebase. The 'filter_results' method is a key candidate for extraction.",
            "status": "pending",
            "testStrategy": "Develop pre-refactoring characterization tests to capture the existing behavior of filtering functions. After refactoring, ensure all existing unit and integration tests covering filtering logic pass without regressions."
          },
          {
            "id": 2,
            "title": "Split 'smart_retrieval.py' into cohesive modules",
            "description": "Decompose the large 'smart_retrieval.py' module into smaller, single-responsibility modules, each handling a specific retrieval concern (e.g., retriever initialization, search execution, batch search) for better organization.",
            "dependencies": [],
            "details": "Analyze 'smart_retrieval.py' along with associated components like 'BaseRetriever' and 'get_retriever' to identify core responsibilities. Create new modules such as 'retriever_factory.py', 'base_retriever_interface.py', and specific retriever implementations (e.g., 'dense_retriever.py', 'bm25_retriever.py'). Update all imports accordingly.",
            "status": "pending",
            "testStrategy": "Implement pre-refactoring characterization tests to document the current behavior of the retrieval system. Post-refactoring, verify that all existing retrieval-related unit and integration tests pass and that integration with other modules remains functional."
          },
          {
            "id": 4,
            "title": "Simplify 'setup_environment' function",
            "description": "Break down the high-complexity 'setup_environment' function into smaller, single-responsibility methods to improve readability, testability, and maintainability.",
            "dependencies": [],
            "details": "The current 'setup_environment' function performs multiple operations, including Prometheus URL validation, AWS region validation, and AWS credential setup/testing. Create separate, focused helper functions for each of these concerns: '_validate_prometheus_url(config)', '_validate_aws_region(config)', '_setup_aws_credentials(config)'. The main 'setup_environment' function will then orchestrate calls to these new helpers.",
            "status": "pending",
            "testStrategy": "Write dedicated unit tests for each newly created helper function to ensure correct validation and setup logic, covering both typical cases and error conditions. An integration test for the main 'setup_environment' function will verify overall flow."
          },
          {
            "id": 5,
            "title": "Break down 'migrate_sqlite_to_json' function",
            "description": "Decompose the hypothetical 'migrate_sqlite_to_json' function into distinct sub-functions covering database connection, data extraction, JSON serialization, and file writing to improve modularity and error handling.",
            "dependencies": [],
            "details": "Assuming 'migrate_sqlite_to_json' currently handles the entire process, create granular functions such as '_connect_to_sqlite(db_path)', '_extract_data_from_db(connection)', '_serialize_data_to_json(data)', and '_write_json_to_file(json_data, filename)'. The main migration function will then coordinate these smaller, focused steps.",
            "status": "pending",
            "testStrategy": "Create unit tests for each sub-function, employing mocks for external dependencies like database connections and file I/O to ensure isolated testing. Develop integration tests to validate the complete migration pipeline."
          }
        ]
      },
      {
        "id": 7,
        "title": "Align and Architecturally Integrate Feature Branches with Justified Targets",
        "description": "Systematically align multiple feature branches with their *explicitly justified* primary integration targets (main, scientific, or orchestration-tools). This involves carefully determining the optimal target based on shared common history and codebase similarity, *and renaming branches with similar names but different codebases to match their content or target first*. This alignment process will ensure code consistency, reduce future merge conflicts, and propagate the latest changes. It will also *prioritize the architectural solutions of the source feature branch if more advanced*, documenting any necessary partial updates to the target branch's architecture. Changes, including conflict resolution and architectural adaptation, *will be performed directly on the feature branch*, with no intermediate alignment branches created. This is an alignment task to resolve architectural mismatches, not a direct merge for large drifts, ensuring no regressions.",
        "status": "pending",
        "dependencies": [
          1
        ],
        "priority": "high",
        "details": "This high-priority task involves a coordinated effort to bring all active feature branches up-to-date with their determined optimal integration target branch.\n\n0.  **Determine Optimal Integration Target**: For each active feature branch, analyze its Git history and codebase similarity to `main`, `scientific`, and `orchestration-tools` to identify the most suitable integration target. This must be explicitly justified for each branch. If branches have similar names but different codebases, they should be renamed to match their content and/or target first. This alignment task aims to resolve architectural mismatches, not perform direct merges with large drift.\nCrucially, *this process avoids defaulting to 'scientific' as the target branch; the optimal integration target will depend entirely on the specifics of each branch*. Any changes, including conflict resolution and architectural adaptation, will be performed directly on the respective feature branch. The branch is considered 'finished' for alignment purposes once these changes are merged back into it, without the creation of extra, intermediate branches.\n\nPart 1: Feature Branch Assessment\n- Use `git branch --remote` and `git log` to identify all active branches diverging from 'scientific'.\n- Create a shared checklist (e.g., a repository markdown file) of branches to be aligned, including: `feature/backlog-ac-updates`, `docs-cleanup`, `feature/search-in-category`, `feature/merge-clean`, `feature/merge-setup-improvements`. Exclude `fix/import-error-corrections` as it's handled by Task 11. \n- Prioritize the branches based on importance and complexity of divergence.\n\nPart 2: Alignment Execution\n- For each branch, create a local backup first (e.g., `git branch <branch-name>-backup-pre-align`).\n- Check out the feature branch (`git checkout <feature-branch>`).\n- For public or shared branches, integrate changes *from* the determined target branch *into* the feature branch (e.g., `git merge <determined_target_branch>` or `git rebase <determined_target_branch>`). All changes, including conflict resolution, must be performed directly on the feature branch. No intermediate alignment branches will be created.\n- Systematically resolve any merge conflicts, using visual merge tools for clarity. Document complex resolutions in the merge commit message. Ensure the changes do not result in regression. If the source branch has a more advanced local architecture for the feature being integrated, that should be preferred, and the architecture of the target branch may need partial updating, which should be noted in documentation in the branch during the final PR.\n\nPart 3: Validation and Documentation\n- After each successful alignment, push the updated feature branch to the remote repository.\n- Create a Pull Request for each aligned feature branch to its determined optimal integration branch to allow for code review and automated CI checks.\n- Update the central alignment checklist to reflect the status of each branch.\n\n\n## Target Branch Context\n- Target: (determined per feature branch)\n- Source of latest changes for alignment: (e.g., `main`, `scientific`, `orchestration-tools` as determined)\n\n\n\n## Implementation Steps\n1. Identify all active feature branches that need alignment\n2. Create alignment plan for each feature branch\n3. Perform merges/rebases as appropriate\n4. Resolve conflicts systematically\n5. Validate functionality after alignment\n## Implementation Steps\n### Part 1: Feature Branch Assessment\n1. List all active feature branches\n2. Identify branches that have diverged significantly from scientific\n3. Assess complexity of alignment for each branch\n4. Prioritize branches based on importance and complexity\n### Part 2: Alignment Execution\n1. For each feature branch, create backup before alignment\n2. Perform merge/rebase with scientific branch\n3. Resolve conflicts following project standards\n4. Test functionality after alignment\n5. Update branch with aligned changes\n### Part 3: Validation and Documentation\n1. Verify all aligned branches build and run correctly\n2. Run relevant test suites for each branch\n3. Document alignment process for future reference\n4. Update backlog tasks to reflect new state\n\n### Tags:\n- `work_type:code-alignment`\n- `component:git-workflow`\n- `scope:devops`, `branch-management`\n- `purpose:consistency`, `merge-stability`",
        "testStrategy": "Validation will focus on ensuring no regressions are introduced during the alignment process.\n1. Before beginning alignment on a branch, run its existing test suite to establish a baseline.\n2. After the merge/rebase is completed and all conflicts are resolved locally, run the full project test suite and specific feature tests to ensure it is fully functional. All tests must pass. Ensure the changes do not result in regression.\n3. Perform a manual smoke test on the core functionality provided by the feature branch to ensure it has not been broken by the merge.\n4. Upon pushing the aligned branch and opening a PR, the continuous integration (CI) pipeline must pass all checks, including linting, unit tests, and integration tests. This CI pass is a mandatory success criterion for each branch.",
        "subtasks": [
          {
            "id": 1,
            "title": "Identify Divergent Branches and Create Alignment Plan",
            "description": "Analyze all remote feature branches to identify which have diverged from their optimal integration target. Document these branches in a new markdown file to serve as a master checklist for the alignment process.",
            "dependencies": [],
            "details": "Use `git branch --remote` and `git log` to identify all active branches. For each branch, analyze its history and codebase to explicitly determine its optimal integration target (`main`, `scientific`, or `orchestration-tools`) based on shared history and codebase similarity. This determination must be explicitly justified for each branch. If branches have similar names but different codebases, they should be renamed to match their content and/or target first. Create a new file named `ALIGNMENT_CHECKLIST.md` in the project root. List the branches to be aligned, including `feature/backlog-ac-updates`, `docs-cleanup`, `feature/search-in-category`, `feature/merge-clean`, and `feature/merge-setup-improvements`. Exclude `fix/import-error-corrections` as it's handled by Task 11. Add columns for target branch, status, notes, and justification for the chosen target.",
            "status": "pending",
            "testStrategy": "Verify the generated `ALIGNMENT_CHECKLIST.md` file is present in the repository and accurately lists all the feature branches mentioned in the task description, along with their determined target branches and justifications."
          },
          {
            "id": 2,
            "title": "Create Local Backups of All Targeted Feature Branches",
            "description": "Before initiating any merge operations, create local backup copies of all feature branches listed in the alignment checklist. This provides a critical safety net and a simple rollback point.",
            "dependencies": [
              1
            ],
            "details": "For each branch identified in `ALIGNMENT_CHECKLIST.md`, execute the command `git branch <branch-name>-backup-pre-align`. For example, for 'feature/backlog-ac-updates', run `git branch feature/backlog-ac-updates-backup-pre-align`. Verify backup creation with `git branch`.",
            "status": "pending",
            "testStrategy": "Run `git branch | grep -- '-backup-pre-align'` locally to confirm that a backup has been created for every branch listed in the alignment checklist."
          },
          {
            "id": 3,
            "title": "Align 'feature/backlog-ac-updates' by Integrating Changes from its Determined Target Branch",
            "description": "Perform a merge of changes from the determined target branch (e.g., 'scientific') into the 'feature/backlog-ac-updates' branch, incorporating the latest stable changes. This will be done directly on the feature branch.",
            "dependencies": [
              2
            ],
            "details": "First, checkout the feature branch (`git checkout feature/backlog-ac-updates`). Then, integrate changes *from* the determined target branch *into* `feature/backlog-ac-updates` (e.g., `git merge <determined_target_branch>` or `git rebase <determined_target_branch>`). Systematically resolve any merge conflicts that arise using a visual merge tool. Document complex resolutions in the merge commit message. If `feature/backlog-ac-updates` has a more advanced architecture for its specific features, its architectural approach will be preferred, and any required partial updates to the target branch's architecture to accommodate this will be noted for the final PR documentation. All changes, including conflict resolution and architectural adaptation, must be performed directly on `feature/backlog-ac-updates`. No intermediate alignment branches will be created.",
            "status": "pending",
            "testStrategy": "Run the project's test suite on the branch before the merge to establish a baseline. After the merge and conflict resolution, run the full test suite again to ensure no regressions have been introduced."
          },
          {
            "id": 4,
            "title": "SKIPPED: 'fix/import-error-corrections' alignment is handled by Task 11",
            "status": "deferred",
            "description": "This subtask is deferred as the alignment of 'fix/import-error-corrections' is explicitly handled by Task 11, which aligns it with the 'main' branch.",
            "dependencies": [
              2
            ],
            "details": "The branch 'fix/import-error-corrections' is covered by Task 11. No action required in this subtask.",
            "testStrategy": "Verify that Task 11 is actively tracking the alignment of 'fix/import-error-corrections' and that this branch is correctly excluded from the scope of Task 7."
          },
          {
            "id": 5,
            "title": "Align 'feature/search-in-category' by Integrating Changes from its Determined Target Branch",
            "description": "Merge the latest changes from its determined target branch directly into the 'feature/search-in-category' branch, resolving any resulting conflicts. This will be done directly on the feature branch.",
            "dependencies": [
              2
            ],
            "details": "Switch to the feature branch with `git checkout feature/search-in-category`. Then, integrate changes *from* the determined target branch *into* `feature/search-in-category` (e.g., `git merge <determined_target_branch>` or `git rebase <determined_target_branch>`). Resolve all merge conflicts and ensure the new search functionality integrates correctly with the latest base code from the target. If `feature/search-in-category` has a more advanced architectural pattern for its specific features, its architectural approach will be preferred, and any required partial updates to the target branch's architecture to accommodate this will be noted for the final PR documentation. All changes, including conflict resolution and architectural adaptation, must be performed directly on `feature/search-in-category`. No intermediate alignment branches will be created.",
            "status": "pending",
            "testStrategy": "Run existing tests on the branch to get a baseline. After the merge, run the full test suite. Additionally, perform a manual smoke test of the search-in-category feature to confirm its behavior remains correct."
          },
          {
            "id": 6,
            "title": "Align Remaining Minor Branches by Integrating Changes from their Determined Target Branches",
            "description": "Perform the alignment process for the remaining, lower-priority branches: 'docs-cleanup', 'feature/merge-clean', and 'feature/merge-setup-improvements', by directly integrating changes from their determined target branches into each feature branch.",
            "dependencies": [
              2
            ],
            "details": "Sequentially process each branch (`docs-cleanup`, `feature/merge-clean`, `feature/merge-setup-improvements`). For each one, use `git checkout <branch-name>`, then integrate changes *from* the determined target branch *into* the current feature branch (e.g., `git merge <determined_target_branch>` or `git rebase <determined_target_branch>`). Resolve any conflicts that may arise. If a feature branch has a more advanced architectural pattern for its specific features, its architectural approach will be preferred, and any required partial updates to the target branch's architecture to accommodate this will be noted for the final PR documentation. All changes, including conflict resolution and architectural adaptation, must be performed directly on each respective feature branch. No intermediate alignment branches will be created.",
            "status": "pending",
            "testStrategy": "For 'docs-cleanup', a visual inspection of rendered documentation changes is sufficient. For 'feature/merge-clean' and 'feature/merge-setup-improvements', the full project test suite must be run post-merge to validate integrity."
          },
          {
            "id": 7,
            "title": "Push Aligned Branches and Create Pull Requests",
            "description": "Push all the locally merged and validated feature branches to the remote repository. Create a corresponding Pull Request from each aligned feature branch to its determined optimal integration branch, enabling code review and triggering CI/CD pipelines.",
            "dependencies": [
              4,
              6
            ],
            "details": "For each successfully aligned feature branch, run `git push origin <branch-name>`. Subsequently, navigate to the repository's web UI and create a Pull Request *from* each aligned feature branch, targeting its determined optimal integration branch. Ensure the PR description explicitly includes details on architectural decisions made during alignment and any partial updates required for the target branch's architecture to integrate the advanced feature branch's approach.",
            "status": "pending",
            "testStrategy": "Confirm that a new Pull Request exists for each aligned branch. Check that the PR's 'Files changed' tab correctly reflects the merge from the target branch and that CI checks have been automatically triggered."
          },
          {
            "id": 8,
            "title": "Final Validation, Review, and Checklist Completion",
            "description": "Monitor the CI pipelines for all created Pull Requests, address any feedback from code reviews, and update the master checklist to reflect the completion of each branch alignment.",
            "dependencies": [
              1,
              7
            ],
            "details": "Review the CI build logs for each PR to ensure all tests pass. Address any code review comments by pushing new commits to the respective branches. After a PR is fully validated and approved, update its status to 'Completed' in the `ALIGNMENT_CHECKLIST.md` file.",
            "status": "pending",
            "testStrategy": "Final validation is successful when all created PRs have a 'green' build status, have been approved by at least one reviewer, and the `ALIGNMENT_CHECKLIST.md` file is updated to show all branches as 'Completed'."
          }
        ]
      },
      {
        "id": 8,
        "title": "Integrate `feature-notmuch-tagging-1` into `scientific` with Architecture Alignment",
        "description": "Execute a comprehensive integration of the `feature-notmuch-tagging-1` branch's functionalities into the `scientific` branch. This process involves first aligning `feature-notmuch-tagging-1` with `scientific`'s architectural and common files, then deeply integrating its enhanced NotmuchDataSource, AI analysis, smart tagging, and full CRUD operations. Significant refactoring will ensure scalability, fault tolerance, and compatibility with existing data structures, while carefully preserving and optimizing the feature branch's distinct functionalities. Attention will be paid to data model evolution, performance, and security hardening, especially prioritizing `feature-notmuch-tagging-1`'s architectural solutions if they are more advanced.",
        "status": "pending",
        "dependencies": [
          1,
          4
        ],
        "priority": "high",
        "details": "The `scientific` branch is the designated target for the integration of `feature-notmuch-tagging-1`. The `feature-notmuch-tagging-1` branch is first prepared by integrating changes from `scientific`, and then its unique features are merged into `scientific`.\n\n1.  **Strategic Branch Alignment & Conflict Resolution:** Initiate by first rebasing `feature-notmuch-tagging-1` directly onto the latest `scientific` branch, applying changes and resolving conflicts *on* `feature-notmuch-tagging-1`. Then, integrate the refined functionalities *from* `feature-notmuch-tagging-1` *into* `scientific` via a merge, resolving any remaining conflicts directly on `scientific`. Document all non-trivial conflict resolutions. If `feature-notmuch-tagging-1` exhibits a more advanced architectural pattern for its specific functionalities, its design will be preferred, and `scientific`'s architecture will be partially updated to accommodate it, with these changes documented for the final PR.\n2.  **NotmuchDataSource Integration & Optimization:** Integrate and optimize the `NotmuchDataSource` from the `feature-notmuch-tagging-1` branch. Ensure its implementation adheres to the existing `DataSource` interface and that its `delete_email`, `get_dashboard_aggregates`, and `get_category_breakdown` methods are performant and compatible with existing data structures. Focus on optimizing the feature branch's data retrieval and processing logic within the current data platform capabilities.\n3.  **AI Analysis & Tagging Logic Integration:** Integrate the AI-powered sentiment analysis and categorization logic from `feature-notmuch-tagging-1` into the `scientific` branch's existing AI processing framework. Ensure the feature branch's AI logic is integrated as a background process and that its output (e.g., AI-derived tags) is correctly stored and linked within existing data models.\n4.  **SmartFilterManager Compatibility:** Ensure the smart tagging logic from `feature-notmuch-tagging-1` is fully compatible with and leverages the existing `SmartFilterManager`. Adapt the feature branch's rule application to use existing SmartFilterManager mechanisms.\n5.  **Tagging and Category Management Integration:** Integrate the feature branch's logic for tag-based category mapping, ensuring it aligns with existing category management systems and data models. Provide CRUD operations for tags and categories inherent to the `feature-notmuch-tagging-1`'s scope.\n6.  **Observability & Monitoring Integration:** Ensure that the integrated `feature-notmuch-tagging-1` components (DataSource, AI logic, tagging) correctly utilize the `scientific` branch's existing logging and monitoring infrastructure. Verify that relevant logs are generated and available in the centralized logging solution, and that basic performance metrics for its operations can be observed.\n7.  **Security Framework Alignment:** Ensure that all new data entry points or internal processing introduced by the `feature-notmuch-tagging-1` branch adhere to existing security standards, including input sanitization and API authentication/authorization for any newly exposed internal endpoints from the feature.\n8.  **Database Layer Compatibility:** Update `src/core/database.py` with any necessary adjustments for compatibility with the integrated `NotmuchDataSource`, focusing on using existing data types and query patterns. Ensure transactional integrity for all tagging and AI-related operations introduced by the feature branch.\n9.  **API Exposure & Documentation:** If `feature-notmuch-tagging-1` exposes new capabilities via API endpoints, ensure these are robust, versioned, and documented using OpenAPI/Swagger, adhering to existing security considerations and usage examples.\n10. **Comprehensive Documentation:** Update all relevant design documents, architectural diagrams, and user guides to reflect the integrated `NotmuchDataSource` capabilities, AI integration, and tagging system from the `feature-notmuch-tagging-1` branch.\n\nAll pre-integration alignment work (rebase, conflict resolution) will be performed directly on the `feature-notmuch-tagging-1` branch. The subsequent integration of `feature-notmuch-tagging-1`'s features into `scientific` will be managed through a Pull Request, ensuring the final changes are applied directly to `scientific`.\n\n### Scope Creep Note:\nThis task encompasses a very broad scope, combining branch alignment with the integration of multiple features (NotmuchDataSource, AI analysis, smart tagging, category management) and significant cross-cutting concerns such as scalability, fault tolerance, performance, security hardening, and observability. It is highly recommended to split this into several smaller, more focused tasks (e.g., one for core feature integration, separate tasks for observability, security alignment, and deeper refactoring initiatives) to improve manageability and track progress more effectively.\n\n### Tags:\n- `work_type:feature-integration`\n- `refactoring`\n- `component:notmuch-data-source`, `ai-platform`\n- `scope:scientific-branch`, `data-platform`\n- `purpose:feature-enhancement`, `scalability`, `security`, `architectural-alignment`",
        "testStrategy": "A rigorous and multi-layered testing strategy is required to ensure the stability, correctness, performance, and security of this complex integration:\n1.  **Expanded Regression Test Suite:** Execute a full regression test suite across the entire application to ensure no existing functionality is broken. This must include performance baselining before and after integration to identify any regressions in response times or resource consumption.\n2.  **Detailed Unit & Integration Tests for NotmuchDataSource:** Develop comprehensive unit tests covering all methods of the `NotmuchDataSource`, including edge cases for each (`delete_email`, `get_dashboard_aggregates` with various date ranges and filters, `get_category_breakdown` with empty data). Integration tests should thoroughly verify the `NotmuchDataSource`'s interaction with the actual database and `SmartFilterManager`.\n3.  **Advanced AI/Background Process Validation:** Create specific integration tests to verify the end-to-end flow of the background AI analysis and tagging processes. This includes testing message queue interactions, error handling for failed AI jobs (e.g., malformed input, AI model errors), retry mechanisms, and the persistence of AI-derived metadata. Validate AI model accuracy with a diverse test dataset, tracking false positives and negatives.\n4.  **Smart Filtering & Tagging System Validation:** Develop comprehensive tests for the `SmartFilterManager` and the new hierarchical tagging system. This includes validating dynamic rule creation, application, and persistence, as well as complex category mapping scenarios (e.g., overlapping tags, nested categories, tag deprecation).\n5.  **Observability & Monitoring Integration:** Ensure that the integrated `feature-notmuch-tagging-1` components (DataSource, AI logic, tagging) correctly utilize the `scientific` branch's existing logging and monitoring infrastructure. Verify that relevant logs are generated and available in the centralized logging solution, and that basic performance metrics for its operations can be observed.\n6.  **Comprehensive Security Testing:** Beyond functional security tests, conduct vulnerability scanning, penetration testing simulations (e.g., SQL injection, XSS for new inputs if applicable, broken access control for new endpoints), and data privacy compliance checks. Verify all input sanitization and authorization rules.\n7.  **Performance, Load, and Stress Testing:** Conduct extensive performance testing, including load tests (simulating expected peak usage), stress tests (exceeding peak usage to find breaking points), and soak tests (long-duration tests to detect memory leaks or resource exhaustion). Focus on the `NotmuchDataSource` aggregation methods and AI background processing under high concurrency.\n8.  **Data Migration & Schema Evolution Testing:** Rigorously test any proposed database schema changes or data migrations. This includes testing forward compatibility (new code with old schema) and backward compatibility (old code with new schema, if necessary for rollback plans). Ensure data integrity and consistency throughout the migration process.\n9.  **User Acceptance Testing (UAT):** Plan and execute UAT sessions with key business stakeholders to validate that the new smart tagging, AI analysis results, and filtering capabilities meet business requirements and provide an intuitive user experience.\n10. **Continuous Integration/Continuous Deployment (CI/CD) Integration:** Ensure all newly developed tests, including unit, integration, and security checks, are integrated into the CI/CD pipeline for automated execution on every code change.",
        "subtasks": [
          {
            "id": 1,
            "title": "Perform Strategic Branch Alignment and Conflict Resolution",
            "description": "Initiate by rebasing the `feature-notmuch-tagging-1` branch onto the latest `scientific` branch. Resolve all encountered conflicts directly on `feature-notmuch-tagging-1`. Once conflicts are resolved and the feature branch is aligned, merge the refined `feature-notmuch-tagging-1` into `scientific`, resolving any remaining conflicts. Prioritize `feature-notmuch-tagging-1`'s architectural patterns for its specific functionalities if they are more advanced, documenting these decisions for the final Pull Request.",
            "dependencies": [],
            "details": "Checkout `feature-notmuch-tagging-1`. Run `git rebase scientific`. Systematically resolve all conflicts, ensuring `feature-notmuch-tagging-1`'s architectural strengths are preserved where applicable. Once rebase is clean, switch to `scientific` and run `git merge feature-notmuch-tagging-1`. Resolve any final merge conflicts. Document all non-trivial conflict resolutions, especially those involving architectural choices, in a temporary text file or commit message.",
            "status": "pending",
            "testStrategy": "Verify successful rebase and merge operations. Conduct a sanity check build and run basic tests on the merged `scientific` branch to ensure no immediate regressions after conflict resolution. Review the codebase for any lingering merge markers or incorrect conflict resolutions."
          },
          {
            "id": 2,
            "title": "Integrate NotmuchDataSource and Ensure Database Compatibility",
            "description": "Integrate the `NotmuchDataSource` from `feature-notmuch-tagging-1` into the `scientific` branch. Ensure it fully adheres to the existing `DataSource` interface. Simultaneously, update `src/core/database.py` to ensure compatibility and transactional integrity for all data access patterns introduced by the `NotmuchDataSource`.",
            "dependencies": [
              1
            ],
            "details": "Migrate the `NotmuchDataSource` class definition and its associated files from `feature-notmuch-tagging-1` to `scientific`. Implement or adapt necessary methods (`delete_email`, `get_dashboard_aggregates`, `get_category_breakdown`) to leverage existing data platform capabilities and ensure performance. Modify `src/core/database.py` to support the `NotmuchDataSource`'s data structures and query needs, ensuring existing data types and transactional integrity for its operations. This includes defining new schemas or extending existing ones if required for Notmuch data.",
            "status": "pending",
            "testStrategy": "Develop unit tests for the `NotmuchDataSource` methods (`delete_email`, `get_dashboard_aggregates`, `get_category_breakdown`) to verify correct functionality and data retrieval. Implement integration tests to confirm `NotmuchDataSource` interaction with the database layer via `src/core/database.py` is robust and maintains transactional integrity. Performance tests for data retrieval methods will be conducted using sample Notmuch data."
          },
          {
            "id": 3,
            "title": "Integrate Core AI Analysis and Tagging Logic",
            "description": "Integrate the fundamental AI-powered sentiment analysis and categorization logic from `feature-notmuch-tagging-1` into `scientific`'s existing AI processing framework. Ensure this logic operates as a background process and that its output, such as AI-derived tags, is correctly stored and linked within the updated data models.",
            "dependencies": [
              2
            ],
            "details": "Extract the core AI analysis and tagging algorithms and integrate them into `scientific`'s AI processing infrastructure (e.g., using existing NLP models or `PromptEngineer` concepts if applicable). Configure the AI logic to run as a background process, potentially leveraging existing task queues or asynchronous processing mechanisms. Define and implement the data structures to store AI-derived tags and ensure they are linked correctly to the `NotmuchDataSource` entities. Update relevant data models to accommodate new tag attributes.",
            "status": "pending",
            "testStrategy": "Create unit tests for the AI analysis components, focusing on the accuracy of sentiment analysis and categorization for sample inputs. Implement integration tests to verify the background processing of the AI logic and the correct storage and linking of generated tags to the Notmuch data entities in the database. Test the retrieval of AI-derived tags through the `NotmuchDataSource` to confirm data integrity."
          }
        ]
      },
      {
        "id": 9,
        "title": "Create Comprehensive Merge Validation Framework",
        "description": "Create a comprehensive validation framework to ensure all architectural updates have been properly implemented before merging scientific branch to main. This framework will leverage research-backed CI/CD practices to validate consistency, functionality, performance, and security across all components, specifically tailored for our Python/FastAPI application. This task is directly linked to the backlog item: `backlog/tasks/alignment/create-merge-validation-framework.md`.",
        "status": "pending",
        "dependencies": [],
        "priority": "high",
        "details": "This framework will integrate into the GitHub Actions CI/CD pipeline, triggered on pull requests to the `main` branch from `scientific`. It will encompass several layers of automated checks, including:\n1.  **Architectural Enforcement**: Static analysis to ensure `src/backend` adheres to defined module boundaries and import rules.\n2.  **Functional Correctness**: Execution of full unit/integration test suites for `src/backend` and end-to-end smoke tests against a deployed instance of the FastAPI application.\n3.  **Performance Benchmarking**: Automated checks for performance regressions on critical FastAPI endpoints.\n4.  **Security Validation**: Dependency vulnerability scanning and Static Application Security Testing (SAST) for the Python/FastAPI codebase.\nThe ultimate goal is to automatically block merges if any of these validation layers fail, ensuring a robust and secure `main` branch. The framework will be configured to analyze the `src/backend` directory primarily.\n\nbuilding upon insights from past branch management efforts and the need for robust pre-merge checks.\n\n## Target Branch Context\n- **Branch:** `scientific`\n- **Based on:** All previous architectural updates completed\n- **Integration target:** Pre-merge validation for main branch\n\n## Action Plan (From Backlog)\n\n### Part 1: Validation Framework Design\n1. Design comprehensive validation approach\n2. Identify key validation points across all components\n3. Create validation checklists\n4. Plan automated vs. manual validation steps\n\n### Part 2: Implementation\n1. Create comprehensive test suite covering all components\n2. Implement performance validation tools\n3. Develop consistency verification scripts\n4. Create validation documentation for team\n\n### Part 3: Validation Execution\n1. Run comprehensive test suite\n2. Execute performance validation checks\n3. Perform consistency verification across components\n4. Document any issues found during validation\n\n### Part 4: Validation Report\n1. Compile validation results\n2. Document any remaining issues\n3. Create merge readiness report\n4. Prepare recommendations for merge process\n\n## Success Criteria (From Backlog)\n- [ ] Comprehensive test suite created and executed\n- [ ] Performance validation completed successfully\n- [ ] Consistency verification passed across all components\n- [ ] Validation report created with merge recommendations\n- [ ] All critical issues addressed before merge\n- [ ] Validation framework documented for future use\n- [ ] PR created with validation framework\n\n## Estimated Effort (From Backlog)\n- 2-3 days: Framework design and implementation\n- 2 days: Validation execution\n- 1 day: Report compilation and documentation\n- 0.5 days: PR creation\n",
        "testStrategy": "The overall test strategy involves validating each component of the framework individually, then ensuring their integrated operation correctly blocks or permits merges based on the validation outcomes. This will include creating test PRs with deliberate failures (architectural, functional, performance, security) and successes to verify the framework's decision-making.",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Validation Scope and Tooling",
            "description": "Establish clear definitions for each validation layer (Architectural Enforcement, Functional Correctness, Performance Benchmarking, Security Validation) including specific metrics, acceptable thresholds, and identify potential tools for implementation (e.g., `ruff`, `flake8` for architectural, `pytest` for functional, `locust` or `pytest-benchmark` for performance, `bandit`, `safety` for security).",
            "dependencies": [],
            "details": "Research and select specific Python static analysis tools, testing frameworks, and security scanning tools that are compatible with FastAPI and GitHub Actions. Document the chosen tools, their configuration requirements, and expected output formats in a `validation_framework_design.md` document.",
            "status": "pending",
            "testStrategy": "Review documentation and tool compatibility. Present findings to the team for approval on tool selection and scope definition."
          },
          {
            "id": 2,
            "title": "Configure GitHub Actions Workflow and Triggers",
            "description": "Set up the foundational GitHub Actions workflow (`.github/workflows/merge-validation.yml`) to trigger on pull requests targeting the `main` branch from the `scientific` branch. Define the necessary environment, including Python version and dependencies for subsequent validation steps.",
            "dependencies": [],
            "details": "Create a new GitHub Actions workflow file. Configure `on: pull_request` with `branches: [main]` and `types: [opened, synchronize, reopened]`. Set up a job with a Python environment, install required dependencies, and add placeholder steps for future validation checks.",
            "status": "pending",
            "testStrategy": "Create a dummy pull request from `scientific` to `main` with minimal changes and verify that the GitHub Actions workflow is triggered correctly and completes the initial setup steps without errors."
          },
          {
            "id": 3,
            "title": "Implement Architectural Enforcement Checks",
            "description": "Integrate static analysis tools into the CI pipeline to enforce architectural rules, module boundaries, and import consistency within the `src/backend` directory. This includes checks for circular dependencies, forbidden imports, and adherence to defined layering.",
            "dependencies": [
              1,
              2
            ],
            "details": "Configure selected static analysis tools (e.g., `ruff` with custom rules, `flake8` with plugins, or `mypy`) within the GitHub Actions workflow. Define specific rules for the `src/backend` directory regarding module dependencies and import patterns. Ensure failures are reported to GitHub PR status checks.",
            "status": "pending",
            "testStrategy": "Introduce deliberate architectural violations (e.g., circular import, forbidden module import) into a test branch's `src/backend` code, create a PR, and verify that the CI pipeline correctly identifies and fails on these violations."
          },
          {
            "id": 4,
            "title": "Integrate Existing Unit and Integration Tests",
            "description": "Configure the CI/CD pipeline to execute the full suite of existing unit and integration tests for the `src/backend` application. Ensure test failures block the merge process.",
            "dependencies": [
              1,
              2
            ],
            "details": "Add a step to the GitHub Actions workflow to run `pytest` for the `src/backend` directory. Ensure `pytest` is configured to collect all relevant unit and integration tests and that its exit code correctly reflects test success or failure, impacting the PR status.",
            "status": "pending",
            "testStrategy": "Introduce a failing unit test and a failing integration test into a test branch. Create a PR and confirm that the CI pipeline executes the tests, identifies the failures, and marks the PR as failing due to these tests."
          },
          {
            "id": 5,
            "title": "Develop and Implement End-to-End Smoke Tests",
            "description": "Create and integrate end-to-end (E2E) smoke tests against a temporarily deployed instance of the FastAPI application. These tests should cover critical user flows and API endpoints to verify overall application health.",
            "dependencies": [
              1,
              2
            ],
            "details": "Develop a set of E2E smoke tests using a framework like `pytest` with `httpx` or `requests`. Implement a temporary deployment strategy within the CI pipeline (e.g., using Docker Compose services or a lightweight deployment to a staging environment) to make the FastAPI application accessible for testing. Execute these tests and report results.",
            "status": "pending",
            "testStrategy": "Deploy a known-good version of the application and run smoke tests to ensure they pass. Then, introduce a bug that breaks a critical API endpoint and verify that the E2E tests correctly detect the failure and block the PR."
          },
          {
            "id": 6,
            "title": "Implement Performance Benchmarking for Critical Endpoints",
            "description": "Set up automated performance benchmarking within the CI pipeline for critical FastAPI endpoints to detect regressions. Define baseline metrics and compare current PR performance against them.",
            "dependencies": [
              1,
              2
            ],
            "details": "Integrate a performance testing tool (e.g., `locust`, `pytest-benchmark`, or a custom script) into the GitHub Actions workflow. Identify critical FastAPI endpoints based on traffic/business logic. Configure the tool to run a short benchmark, capture key metrics (e.g., response time, throughput), and compare them against established baselines. Implement a mechanism to fail the build if performance degrades beyond a defined threshold.",
            "status": "pending",
            "testStrategy": "Establish initial performance baselines for critical endpoints. Introduce a synthetic performance degradation (e.g., adding an intentional delay to an endpoint) in a test branch, create a PR, and confirm the benchmark job detects the regression and fails the PR check."
          },
          {
            "id": 7,
            "title": "Integrate Security Scans (SAST and Dependency)",
            "description": "Incorporate Static Application Security Testing (SAST) and dependency vulnerability scanning into the CI pipeline for the Python/FastAPI codebase. Ensure identified high-severity vulnerabilities block merges.",
            "dependencies": [
              1,
              2
            ],
            "details": "Configure SAST tools (e.g., `bandit`, `pylint` with security checks, or a commercial tool via GitHub Action) to scan the `src/backend` codebase. Integrate dependency vulnerability scanners (e.g., `safety`, `pip-audit`, or GitHub's Dependabot/Security Alerts) to check `requirements.txt` or `pyproject.toml`. Configure these tools to fail the CI job if critical security issues are detected.",
            "status": "pending",
            "testStrategy": "Introduce a known high-severity vulnerability (e.g., using an insecure version of a library or a common SAST pattern) into a test branch. Create a PR and verify that the security scans correctly identify the vulnerability and block the merge."
          },
          {
            "id": 8,
            "title": "Consolidate Validation Results and Reporting",
            "description": "Develop a mechanism to consolidate results from all validation layers (architectural, functional, E2E, performance, security) into a unified report or a clear summary within the GitHub PR checks interface.",
            "dependencies": [
              3,
              4,
              6,
              7
            ],
            "details": "Utilize GitHub Actions' summary features, custom scripts, or third-party integrations to aggregate outputs from all validation jobs. Create a concise summary indicating overall pass/fail status and direct links to detailed reports for each validation type. Ensure clear feedback is provided on PRs.",
            "status": "pending",
            "testStrategy": "Run a PR with a mix of passing and failing validation checks. Verify that the GitHub PR status checks accurately reflect the overall outcome and that the summary report clearly indicates which specific checks passed or failed."
          },
          {
            "id": 9,
            "title": "Configure GitHub Branch Protection Rules",
            "description": "Configure GitHub Branch Protection Rules for the `main` branch to enforce that all required CI/CD validation checks must pass before a pull request from `scientific` can be merged.",
            "dependencies": [
              8
            ],
            "details": "Access GitHub repository settings, navigate to 'Branches', and configure protection rules for the `main` branch. Enable 'Require status checks to pass before merging' and select all relevant status checks generated by the merge validation framework. Ensure 'Require branches to be up to date before merging' is also enabled.",
            "status": "pending",
            "testStrategy": "Create a PR from `scientific` to `main` that intentionally fails one or more validation checks. Attempt to merge it and confirm that GitHub's branch protection rules prevent the merge. Then, fix the failure, re-run CI, and verify that the PR can now be merged."
          },
          {
            "id": 10,
            "title": "Implement Architectural Static Analysis for `src/backend`",
            "description": "Set up a static analysis tool within the GitHub Actions CI pipeline to enforce defined module boundaries and import rules specifically for the `src/backend` directory. This will ensure architectural consistency.",
            "dependencies": [],
            "details": "Configure a static analysis tool (e.g., Ruff with custom rules, Pylint, or a dedicated architectural linter like `import-linter`) to scan Python files within `src/backend`. Define clear rules for module dependencies and allowed imports. Integrate this check into the existing `.github/workflows/ci.yml` or a new dedicated workflow triggered on PRs to `main` to fail the build if violations are detected.",
            "status": "pending",
            "testStrategy": "Create a new branch and introduce a deliberate architectural violation (e.g., an unauthorized import) within `src/backend`. Create a pull request to `main` and verify that the CI pipeline fails due to the static analysis check."
          },
          {
            "id": 11,
            "title": "Integrate and Automate `src/backend` Functional Test Execution in CI",
            "description": "Ensure all existing unit and integration test suites for the `src/backend` application are automatically executed as a mandatory step in the GitHub Actions CI pipeline for pull requests to the `main` branch.",
            "dependencies": [],
            "details": "Review the current `pytest` setup for `src/backend`. Ensure test coverage reporting is configured (e.g., using `pytest-cov`). Add or update a step in the GitHub Actions workflow to run these tests, failing the PR if any tests fail or if the configured test coverage threshold is not met. This ensures functional correctness before merging.",
            "status": "pending",
            "testStrategy": "Create a new branch, introduce a small bug in a `src/backend` module that causes an existing unit test to fail. Create a pull request to `main` and verify that the CI pipeline fails at the functional test execution step."
          },
          {
            "id": 12,
            "title": "Develop and Integrate E2E Smoke Tests for FastAPI in CI",
            "description": "Implement a suite of essential end-to-end smoke tests that validate the core functionality and critical API endpoints of the deployed FastAPI application, and integrate their execution into the CI pipeline.",
            "dependencies": [],
            "details": "Select an appropriate testing framework (e.g., `pytest` with `httpx` or Playwright for API interactions). Define key API endpoints and critical user flows that represent the application's core functionality. Set up a GitHub Actions workflow that can temporarily deploy the FastAPI application (or connect to a staging instance) and execute these smoke tests, blocking the merge if any fail.",
            "status": "pending",
            "testStrategy": "Introduce a breaking change to a critical FastAPI endpoint in a test branch. Create a pull request and ensure the E2E smoke tests fail, correctly blocking the merge."
          },
          {
            "id": 13,
            "title": "Set Up Performance Benchmarking for Critical FastAPI Endpoints",
            "description": "Implement automated performance benchmarking for identified critical FastAPI endpoints to detect any performance regressions before merging to the `main` branch.",
            "dependencies": [],
            "details": "Identify the top N (e.g., 5-10) most critical or frequently accessed FastAPI endpoints. Choose and configure a suitable benchmarking tool (e.g., `locust`, `pytest-benchmark`, `k6`). Integrate this tool into the GitHub Actions CI pipeline to run against a deployed instance. Define acceptable performance thresholds and configure the workflow to fail if these thresholds are exceeded by the new changes.",
            "status": "pending",
            "testStrategy": "In a test branch, introduce a deliberate performance bottleneck in one of the benchmarked critical endpoints (e.g., an inefficient database query). Create a pull request and verify that the performance benchmarking step fails, indicating a regression and blocking the merge."
          },
          {
            "id": 14,
            "title": "Integrate Security Validation (Dependency Scan & SAST) into CI",
            "description": "Implement automated security checks within the CI pipeline, including dependency vulnerability scanning and Static Application Security Testing (SAST), to ensure the `src/backend` codebase is secure before merging.",
            "dependencies": [],
            "details": "Integrate tools like `safety`, `pip-audit`, or a similar dependency scanner to check `requirements.txt` or `pyproject.toml`. Additionally, integrate a SAST tool like `Bandit` to scan the `src/backend` Python code for common security issues. Configure these tools within the GitHub Actions workflow to fail the PR if critical or high-severity vulnerabilities/issues are found.",
            "status": "pending",
            "testStrategy": "Create a new branch and deliberately introduce a known vulnerable dependency (e.g., an older version of a package with a documented CVE) or a common SAST pattern that `Bandit` would flag. Create a pull request to `main` and verify that the security validation step fails, blocking the merge."
          }
        ],
        "notes": "## Notes (From Backlog)\n- This is the final validation step before merge\n- Requires coordination with multiple team members\n- Should catch any remaining architectural inconsistencies\n- Framework should be reusable for future branch alignments"
      },
      {
        "id": 11,
        "title": "Align import-error-corrections Branch with Main Branch",
        "description": "Systematically align the `fix/import-error-corrections` branch with the `main` branch. This alignment will involve first bringing `fix/import-error-corrections` up-to-date with `main`'s current architecture and common files, and then integrating the feature branch's specific import error corrections into `main`. The architectural approach for the import error corrections within `fix/import-error-corrections` will be preferred if it represents a more robust solution, potentially requiring partial updates to `main`'s architecture.",
        "status": "pending",
        "dependencies": [],
        "priority": "low",
        "details": "This task involves aligning `fix/import-error-corrections` with the `main` branch, which is identified as its most suitable integration target due to shared history and codebase similarity. The process will involve both updating `fix/import-error-corrections` from `main` and then integrating its specific changes into `main`.\n\nThis alignment task aims to resolve architectural mismatches, not perform a direct merge with potentially large drift. If the architectural approach implemented in `fix/import-error-corrections` for resolving import errors is deemed more robust or advanced than `main`'s current structure, it will be prioritized. In such cases, `main`'s architecture may need partial updating to fully accommodate this improved approach. These architectural adjustments will be explicitly documented within the `fix/import-error-corrections` branch's documentation or the final Pull Request description.\n\n## Acceptance Criteria\n<!-- AC:BEGIN -->\n- [x] #1 Resolve .gitignore conflicts\n- [x] #2 Resolve README.md conflicts\n- [x] #3 Resolve database.py conflicts\n- [x] #4 Resolve models.py conflicts\n- [x] #5 Resolve launch.py conflicts\n- [x] #6 Resolve pyproject.toml conflicts\n- [x] #7 Resolve requirements.txt conflicts\n- [x] #8 Commit and push the merge\n<!-- AC:END -->\n\n### Tags:\n- `work_type:code-alignment`\n- `component:git-workflow`\n- `scope:branch-management`\n- `purpose:bug-fix`, `code-consistency`",
        "testStrategy": "Validation will focus on ensuring no regressions are introduced during the alignment process.\n1. Before beginning alignment on the branch, run its existing test suite to establish a baseline.\n2. After the rebase is completed and all conflicts are resolved locally, run the full project test suite and specific feature tests to ensure it is fully functional. All tests must pass. Ensure the changes do not result in regression.\n3. Perform a manual smoke test on the core functionality provided by the feature branch to ensure it has not been broken by the rebase.\n4. Upon pushing the aligned branch and opening a PR, the continuous integration (CI) pipeline must pass all checks, including linting, unit tests, and integration tests. This CI pass is a mandatory success criterion for the branch.",
        "subtasks": [
          {
            "id": 1,
            "title": "Ensure clean working directory and checkout feature branch",
            "description": "Before starting the alignment process, ensure there are no uncommitted changes in the local repository and checkout the target feature branch `fix/import-error-corrections`.",
            "dependencies": [],
            "details": "Use `git status` to confirm a clean working directory. If necessary, stash or commit any local changes. Then, execute `git checkout fix/import-error-corrections`.",
            "status": "pending",
            "testStrategy": null
          },
          {
            "id": 2,
            "title": "Update local 'main' branch to latest remote",
            "description": "Synchronize the local 'main' branch with the upstream 'main' branch to ensure the feature branch will be rebased against the most recent changes.",
            "dependencies": [
              1
            ],
            "details": "First, switch to the main branch (`git checkout main`), then fetch and pull the latest changes from the remote (`git pull origin main`).",
            "status": "pending",
            "testStrategy": null
          },
          {
            "id": 3,
            "title": "Run baseline tests on 'fix/import-error-corrections'",
            "description": "Execute the existing test suite on the `fix/import-error-corrections` branch to establish a functional baseline before applying changes from 'main'.",
            "dependencies": [
              2
            ],
            "details": "Switch back to the feature branch (`git checkout fix/import-error-corrections`). Run all relevant unit, integration, and end-to-end tests for the project. Document any existing failures or unexpected behaviors.",
            "status": "pending",
            "testStrategy": "Capture test results (e.g., screenshots of test runner output, log files) to compare against post-rebase results."
          },
          {
            "id": 4,
            "title": "Rebase 'fix/import-error-corrections' onto 'main'",
            "description": "Perform the Git rebase operation directly on the `fix/import-error-corrections` branch to integrate the `main` branch's history, ensuring a linear commit history.",
            "dependencies": [],
            "details": "While on the `fix/import-error-corrections` branch, execute `git rebase main`. This will apply the commits from the feature branch on top of the latest 'main' commit. All changes, including the rebase operation, must be made directly on `fix/import-error-corrections`.",
            "status": "pending",
            "testStrategy": null
          },
          {
            "id": 5,
            "title": "Resolve rebase conflicts",
            "description": "Address and resolve any merge conflicts that arise during the rebase process directly on the `fix/import-error-corrections` branch to ensure code integrity and functionality.",
            "dependencies": [
              4
            ],
            "details": "Upon encountering conflicts, use `git status` to identify conflicting files. Edit these files to resolve conflicts, then stage them (`git add <file>`) and continue the rebase (`git rebase --continue`). Repeat until the rebase is complete. All conflict resolutions must be applied directly on `fix/import-error-corrections`.",
            "status": "pending",
            "testStrategy": "Thoroughly review each conflict resolution to ensure correct code merging and no introduction of new bugs."
          },
          {
            "id": 6,
            "title": "Run full test suite post-rebase",
            "description": "After successfully rebasing and resolving conflicts, run the entire project's test suite on the `fix/import-error-corrections` branch to verify that no regressions or new issues were introduced.",
            "dependencies": [],
            "details": "Execute all unit, integration, and end-to-end tests on the rebased `fix/import-error-corrections` branch. Compare results with the baseline tests from subtask 3. All tests must be run on the `fix/import-error-corrections` branch.",
            "status": "pending",
            "testStrategy": "All tests must pass. If any tests fail, debug and fix the issues introduced by the rebase, then re-run tests. Document any new issues."
          },
          {
            "id": 7,
            "title": "Perform local functional validation and code review",
            "description": "Conduct a manual review of the aligned code on the `fix/import-error-corrections` branch and perform functional tests specific to the `import-error-corrections` feature to ensure it still works as expected.",
            "dependencies": [
              6
            ],
            "details": "Manually test the `import-error-corrections` functionality. Review the changes introduced from 'main' to ensure they integrate logically with the feature branch's code. Pay attention to any areas that had conflicts. All validation and review must occur on the `fix/import-error-corrections` branch.",
            "status": "pending",
            "testStrategy": "Verify the core functionality addressed by `fix/import-error-corrections` still works correctly. Check for unexpected side effects from the `main` branch's changes."
          },
          {
            "id": 8,
            "title": "Force push rebased branch and notify team",
            "description": "Once validation is complete, force push the rebased `fix/import-error-corrections` branch to the remote repository and inform relevant team members.",
            "dependencies": [
              7
            ],
            "details": "Execute `git push --force-with-lease origin fix/import-error-corrections`. Notify the development team, especially those who might be working on or depending on this branch, about the successful rebase and updated remote branch. This push directly updates the `fix/import-error-corrections` remote branch, making it ready for a Pull Request into `main`. The final integration of `fix/import-error-corrections` into `main` will occur via a standard Pull Request process, where any necessary architectural adaptations for `main` (if `fix/import-error-corrections` has a more robust solution) will be detailed in the PR description.",
            "status": "pending",
            "testStrategy": null
          }
        ]
      },
      {
        "id": 12,
        "title": "Improve Task Management with Advanced Testing Integration",
        "description": "Enhance the Task Master system with advanced testing integration capabilities, including automated testing validation in task completion workflows, branch-specific task tracking and validation, incorporation of scientific branch testing frameworks, and testing requirement enforcement in task creation.",
        "details": "This task focuses on deeply integrating testing and validation processes into our task management and CI/CD pipelines, building upon the foundational 'Comprehensive Merge Validation Framework' established by Task 9. The goal is to enforce quality and consistency from task creation through to completion.\n\n1.  **Automated Testing Validation into Task Completion Workflow:** Enhance existing GitHub Actions workflows (as defined in Task 9 for `scientific` to `main` merges) to automatically validate test results upon pull request merges or task completion markers. This includes integrating coverage checks, static analysis results, and functional test suite outcomes directly into the task status reporting (e.g., via GitHub status checks or a custom webhook to a task tracking system).\n2.  **Adding Branch-Specific Task Tracking and Validation:** Implement mechanisms to differentiate validation rules and required checks based on the target branch (e.g., `main`, `scientific`, feature branches). This could involve conditional GitHub Actions workflows or specific branch protection rules that vary per branch type, ensuring that `scientific` branch merges, for instance, trigger specific 'scientific branch testing frameworks'.\n3.  **Incorporate Scientific Branch Testing Frameworks:** Develop and integrate specialized testing frameworks for the `scientific` branch within the CI/CD pipeline. This may involve setting up dedicated test environments, using specialized data sets for model validation, or incorporating statistical testing and reproducibility checks tailored for scientific computing or AI model evaluation within `src/backend`'s AI components. Leverage existing Python testing frameworks like `pytest` and extend them with custom plugins or reporting.\n4.  **Add Testing Requirement Enforcement in Task Creation:** Implement checks at the pull request creation or task definition stage to ensure testing requirements are met. This could include:\n    *   Pre-commit hooks or GitHub Actions checks requiring new or modified test files (`tests/`) to be present for new features/bug fixes.\n    *   Mandating minimum test coverage thresholds (e.g., via `pytest-cov` and reporting to Codecov/Coveralls) for affected modules in `src/backend` before a PR can be merged.\n    *   Enforcing specific labels or comments in PR descriptions that confirm testing strategy has been addressed.\n\nAll integrations should leverage existing GitHub and Python ecosystem tools where possible to minimize overhead, and refer to `src/backend` for all code-related implementations.\n\n### Tags:\n- `work_type:feature-enhancement`, `ci-cd`\n- `component:testing-infrastructure`, `task-management`\n- `scope:devops`, `quality-assurance`\n- `purpose:quality-enforcement`, `automation`",
        "testStrategy": "A multi-faceted test strategy will be employed to ensure the robust implementation of advanced testing integrations:\n1.  **Unit and Integration Tests:** Develop comprehensive unit tests for any new scripts or code that facilitate these integrations (e.g., custom GitHub Actions, webhook handlers).\n2.  **End-to-End Workflow Tests:** Create specific test scenarios for each integration point:\n    *   **Task Completion Validation:** Create a feature branch, add code, add tests (passing and failing), open a PR, and observe how the CI/CD pipeline (leveraging Task 7's framework) validates and reports task status upon merge attempts.\n    *   **Branch-Specific Validation:** Test PRs targeting `main` vs. `scientific` to ensure different sets of required checks or workflows are correctly triggered and enforced.\n    *   **Scientific Framework Integration:** Run PRs with changes to scientific components (e.g., in `src/backend/ai_engine`) and verify that the specialized scientific testing frameworks execute correctly and report results. This includes testing with expected data variations.\n    *   **Requirement Enforcement:** Attempt to create PRs that intentionally violate testing requirements (e.g., no new tests for new features, low coverage) and confirm that the enforcement mechanisms (CI checks, pre-commit) correctly block the PR or flag the issue.\n3.  **Regression Testing:** Ensure that these new integrations do not adversely affect existing CI/CD pipelines or merge validation processes defined in Task 7.\n4.  **Documentation & User Acceptance:** Verify that the new requirements and workflows are clearly documented and understandable for developers, and conduct internal UAT to confirm usability and effectiveness.",
        "status": "pending",
        "dependencies": [
          7
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Automated testing validation into task completion workflow",
            "description": "Integrate automated testing validation into the task completion workflow to ensure tasks cannot be marked complete without proper testing validation.",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 10
          },
          {
            "id": 2,
            "title": "Adding branch-specific task tracking and validation",
            "description": "Implement branch-aware validation rules in CI/CD service with conditional branch-specific testing for scientific vs standard branches, and task-branch association validation.",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 10
          },
          {
            "id": 3,
            "title": "Incorporate scientific branch testing frameworks into Task Master",
            "description": "Integrate the advanced testing frameworks and practices from the scientific branch into the Task Master system, including enhanced test coverage requirements, scientific-specific test suites, and advanced testing methodologies.",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 10
          },
          {
            "id": 4,
            "title": "Add testing requirement enforcement in task creation",
            "description": "Implement validation rules during task creation to ensure that tasks include appropriate testing requirements, acceptance criteria, and testing strategies based on their complexity and branch context.",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 10
          }
        ]
      },
      {
        "id": 13,
        "title": "Resolve 'test_stages' Module Location Issue",
        "description": "Address the problem where 'deployment/test_stages.py' exists but is imported from 'setup/', causing import errors and inconsistent module organization.",
        "details": "Analyze current import statements across the codebase that reference 'test_stages'. Specifically, use `grep -r \"test_stages\" .` to locate all instances. Determine whether to move `deployment/test_stages.py` to `setup/test_stages.py` or create an appropriate `__init__.py` structure in `deployment/` and update import paths to reflect the correct module location. If moving, ensure all references are updated. If adjusting import paths, ensure Python's module resolution finds it correctly from the 'setup/' package.",
        "testStrategy": "Run all existing unit and integration tests to ensure no new import errors are introduced. Specifically, create a test case that imports `test_stages` from `setup` and verifies its functionality. Validate that the original `deployment/test_stages.py` is no longer incorrectly referenced or that its new path is correctly resolved.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Codebase Scan for 'test_stages' References",
            "description": "Conduct a thorough static analysis of the entire codebase to locate every instance where 'test_stages' is imported or referenced. This includes identifying all files and specific import statements (e.g., 'from setup import test_stages', 'from deployment import test_stages').",
            "dependencies": [],
            "details": "Use global search tools like `grep -r \"test_stages\" .` or IDE's 'Find Usages' functionality to compile a comprehensive list of all references to 'test_stages'. Document the file paths, line numbers, and the exact import syntax used for each reference. This detailed analysis is crucial for understanding the scope and nature of the issue. Focus on imports of `deployment.test_stages` and `setup.test_stages`.\n<info added on 2025-11-12T17:50:33.440Z>\n{\"new_content\": \"Codebase scan for 'test_stages' references completed. Imports were identified in `setup/commands/test_command.py` and `setup/launch.py`. The duplicate file `deployment/test_stages.py` has been removed, and all relevant documentation references have been updated to point to `setup/test_stages.py`.\"}\n</info added on 2025-11-12T17:50:33.440Z>",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Determine Optimal Module Organization Strategy for 'test_stages'",
            "description": "Based on the findings from the codebase scan, evaluate the logical ownership and architectural consistency to determine the best strategy for 'test_stages'. This involves deciding whether to physically move 'deployment/test_stages.py' to 'setup/test_stages.py' or to keep it in 'deployment/' and update import paths.",
            "dependencies": [
              1
            ],
            "details": "Analyze the documented references from Subtask 1. Consider which package ('setup' or 'deployment') 'test_stages' logically belongs to. If it contains setup-related stages, moving it to 'setup/' might be appropriate. If it's deployment-specific, it should remain in 'deployment/'. Document the chosen strategy (Move file or Adjust import paths) and provide a clear justification for the decision, including potential pros and cons of each approach.",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement File System Relocation for 'test_stages' (if applicable)",
            "description": "If the chosen strategy in Subtask 2 is to move the 'test_stages' module, perform the physical file system relocation from 'deployment/test_stages.py' to 'setup/test_stages.py'. This subtask only covers the file movement and initial package setup, not import updates.",
            "dependencies": [
              2
            ],
            "details": "Execute the file movement: `mv deployment/test_stages.py setup/test_stages.py`. Ensure that the `setup/` directory is recognized as a valid Python package by verifying the existence of an empty `setup/__init__.py` file. If it doesn't exist, create it. Similarly, ensure `deployment/` also has an `__init__.py` if it's meant to be a package. This step should be skipped if the decision was to keep the file in `deployment/`.",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Refactor All 'test_stages' Import Statements",
            "description": "Update all identified import statements and direct references to 'test_stages' across the codebase to align with the chosen module organization strategy and the new file location (if moved). This ensures all modules correctly reference 'test_stages' from its intended, final location.",
            "dependencies": [
              2
            ],
            "details": "Iterate through all references identified in Subtask 1. Based on the decision from Subtask 2 and actions in Subtask 3: if 'test_stages.py' was moved to `setup/`, change all `from deployment import test_stages` and any `from setup import test_stages` (if incorrect) to `from setup import test_stages`. If `test_stages.py` remained in `deployment/`, change all `from setup import test_stages` to `from deployment import test_stages`. Ensure `__init__.py` files in `deployment/` and `setup/` are correctly structured for proper package imports.",
            "status": "done",
            "testStrategy": "Run static analysis tools (e.g., pylint, flake8) to check for new import errors. Attempt local imports of 'test_stages' from various entry points in the application to verify module resolution.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Execute Comprehensive Tests and Resolve Integration Issues",
            "description": "After updating all import paths, execute the entire test suite (unit, integration, and any relevant system tests) to confirm that no new import errors have been introduced and that existing functionality remains intact. Address any regressions or unexpected behaviors that arise.",
            "dependencies": [
              4
            ],
            "details": "Run all existing unit tests and integration tests. Perform manual smoke tests on core functionalities that are known to rely on 'test_stages'. Specifically, create or update a dedicated test case in `src/tests/` that explicitly imports 'test_stages' from its final, correct location (e.g., `from setup import test_stages`) and verifies a core piece of its functionality (e.g., calling a known method, accessing an expected attribute). Log and fix any errors or failures promptly.",
            "status": "done",
            "testStrategy": "Run all existing unit and integration tests to ensure no regressions. Create a specific test case that imports the module from its final, correct location (e.g., 'from setup import test_stages') and calls a simple function within it to confirm import success and basic functionality. Verify that the application starts and runs without any import-related exceptions.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Perform Codebase Scan for 'test_stages' References",
            "description": "Utilize `grep -r \"test_stages\" .` to comprehensively locate all import statements, function calls, and any other references to 'test_stages' across the entire codebase. Document the exact lines and files where these references are found.",
            "dependencies": [],
            "details": "Execute `grep -r \"test_stages\" .` from the project root. Pay close attention to `import` and `from` statements. Catalog all found references, noting the current import path (e.g., `from setup import test_stages`, `from deployment import test_stages`). This will form the basis for understanding the scope of required changes.",
            "status": "done",
            "testStrategy": "N/A - this is an analysis subtask. Verification will be manual review of grep output.",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Analyze 'deployment/test_stages.py' Content and Package Structure",
            "description": "Examine the content of `deployment/test_stages.py` to understand its functionalities and dependencies. Additionally, check if `deployment/` directory currently contains an `__init__.py` file, determining if it functions as a Python package.",
            "dependencies": [
              6
            ],
            "details": "Read through `deployment/test_stages.py` to identify key classes, functions, and variables it defines. Assess its role within the application. Check for the presence of `deployment/__init__.py` to confirm or deny `deployment` as a package. This analysis will guide the decision on whether to move the file or adjust package structure.",
            "status": "done",
            "testStrategy": "N/A - this is an analysis subtask. Verification will be manual review of file content and directory structure.",
            "parentId": "undefined"
          },
          {
            "id": 8,
            "title": "Determine Optimal Resolution Strategy for 'test_stages' Module",
            "description": "Based on the codebase scan and content analysis, decide on the definitive strategy to resolve the module location issue: either move `deployment/test_stages.py` to `setup/test_stages.py` or establish `deployment/` as a proper package and update import paths.",
            "dependencies": [
              6,
              7
            ],
            "details": "Consider the following options: 1) Move `deployment/test_stages.py` to `setup/test_stages.py` to align with `from setup import test_stages` imports. This implies `setup` is the intended logical container. 2) Ensure `deployment/__init__.py` exists, making `deployment` a package, and update all `from setup import test_stages` imports to `from deployment import test_stages`. Document the chosen strategy and the rationale.",
            "status": "done",
            "testStrategy": "N/A - this subtask concludes with a decision document rather than code. The decision's effectiveness will be validated in subsequent implementation and test subtasks.",
            "parentId": "undefined"
          },
          {
            "id": 9,
            "title": "Implement Chosen Module Resolution and Update References",
            "description": "Execute the chosen strategy from subtask 8. This involves either relocating `deployment/test_stages.py` to `setup/` and updating all import references, or ensuring `deployment` is a package and updating relevant imports.",
            "dependencies": [
              8
            ],
            "details": "If moving: move `deployment/test_stages.py` to `setup/test_stages.py`. Ensure any pre-existing `setup/test_stages.py` (if any) is merged or handled. Update all files identified in subtask 6 to correctly import `test_stages` from its new location (e.g., `from setup import test_stages`). Delete the original file from `deployment/`. If restructuring: create `deployment/__init__.py` and update all `from setup import test_stages` to `from deployment import test_stages`.",
            "status": "done",
            "testStrategy": "Initial compile/lint checks to catch basic import errors. Manual verification that file has moved and old path no longer exists. No functional tests at this stage.",
            "parentId": "undefined"
          },
          {
            "id": 10,
            "title": "Validate 'test_stages' Functionality and Run All Tests",
            "description": "After implementing the module resolution, run all existing unit and integration tests. Specifically, verify that `test_stages` can be correctly imported and its functionalities remain intact, and no new import errors or regressions are introduced.",
            "dependencies": [
              9
            ],
            "details": "Execute the full test suite (`pytest` or equivalent). Create a dedicated test case (if one doesn't exist) that specifically imports `test_stages` from its resolved location (e.g., `from setup import test_stages`) and calls at least one core function from it to confirm accessibility and functionality. Check logs for any `ModuleNotFoundError` or other import-related issues.",
            "status": "done",
            "testStrategy": "Run all existing unit and integration tests. Develop a new unit test in an appropriate location (e.g., `tests/unit/test_module_resolution.py`) that imports `test_stages` and asserts basic functionality. Verify that the application starts and runs without import-related exceptions.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 5,
        "expansionPrompt": "",
        "updatedAt": "2025-11-12T17:47:45.523Z"
      }
    ],
    "metadata": {
      "created": "2025-11-23T17:29:33.181Z",
      "updated": "2025-11-23T17:29:33.181Z",
      "description": "Tasks for master context"
    }
  }
}

{
  "models": {
    "main": {
      "provider": "openai-compatible",
      "modelId": "llama-3.3-70b-versatile",
      "maxTokens": 32768,
      "temperature": 0.2,
      "baseURL": "https://api.groq.com/openai/v1"
    },
    "research": {
      "provider": "openai-compatible",
      "modelId": "llama-3.3-70b-versatile",
      "maxTokens": 32768,
      "temperature": 0.1,
      "baseURL": "https://api.groq.com/openai/v1"
    },
    "fallback": {
      "provider": "openai-compatible",
      "modelId": "llama-3.1-8b-instant",
      "maxTokens": 8192,
      "temperature": 0.2,
      "baseURL": "https://api.groq.com/openai/v1"
    }
  },
  "global": {
    "logLevel": "info",
    "debug": false,
    "defaultNumTasks": 10,
    "defaultSubtasks": 5,
    "defaultPriority": "medium",
    "projectName": "Taskmaster",
    "ollamaBaseURL": "http://localhost:11434/api",
    "bedrockBaseURL": "https://bedrock.us-east-1.amazonaws.com",
    "responseLanguage": "English",
    "enableCodebaseAnalysis": true,
    "enableProxy": false,
    "anonymousTelemetry": true,
    "defaultTag": "master",
    "azureOpenaiBaseURL": "https://your-endpoint.openai.azure.com/",
    "userId": "1234567890"
  },
  "claudeCode": {},
  "codexCli": {},
  "grokCli": {
    "timeout": 120000,
    "workingDirectory": null,
    "defaultModel": "grok-4-latest"
  }
}